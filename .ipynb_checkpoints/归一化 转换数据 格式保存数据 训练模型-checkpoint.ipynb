{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataset=[]\n",
    "datalen=[]\n",
    "alldata=pd.DataFrame()\n",
    "x,y=[],[]\n",
    "x_Nocharing,y_Nocharing=[],[]\n",
    "LEN_DATASET=132\n",
    "for number in range(LEN_DATASET):\n",
    "    df=pd.read_csv(r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\continueTimedata\"+'\\\\'+str(number)+\".csv\")\n",
    "    dataset.append(df)\n",
    "    datalen.append(len(df))\n",
    "    alldata=pd.concat([alldata,df])\n",
    "    index=df.loc[df.speed==0].loc[df.total_current<0].loc[df.motor_voltage==0].loc[df.motor_current==0].index\n",
    "    x.append(df.iloc[:,4:-3])\n",
    "    y.append(df.iloc[:,[2,-1]])\n",
    "    x_Nocharing.append(df.drop(index).iloc[:,4:-3])\n",
    "    y_Nocharing.append(df.drop(index).iloc[:,[2,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def savemodel(model,name):\n",
    "    path=r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\"+'\\\\'+name+'.pkl'\n",
    "    joblib.dump(model,path)\n",
    "def loadmodel(name):\n",
    "    path=r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\"+'\\\\'+name+'.pkl'\n",
    "    return joblib.load('filename.pkl')\n",
    "#加载数据并且转换成三个时间一条数据的格式，结果添加在给出的conti_X,conti_Y\n",
    "def getTimeSdata2ConBox(dfx,dfy,scaler,number,conti_X,conti_Y,TIMESTEP=3,test=False):\n",
    "    #归一化 这里可以选择手动归一化或者直接使用sklearn的api （这里首先使用api）\n",
    "    X=scaler.transform(dfx[number].to_numpy())\n",
    "    Y=dfy[number].iloc[:,1].to_numpy()\n",
    "    #分成三个数据的array集合\n",
    "    datasize=len(X)\n",
    "    if test:\n",
    "        step=TIMESTEP\n",
    "    else:\n",
    "        step=1\n",
    "    for i in range(0,datasize-TIMESTEP+1,step):\n",
    "        conti_X.append(X[i:i+TIMESTEP])\n",
    "        conti_Y.append(round(Y[i:i+TIMESTEP].sum(),3))\n",
    "    return conti_X,conti_Y\n",
    "#这里要reshape一下 将timestep的分开的数据变成合在一起的数据\n",
    "def timeS2sigle(conti_X,conti_Y,TIMESTEP=3):\n",
    "    XX=np.array(conti_X)\n",
    "    YY=np.array(conti_Y)\n",
    "    FEATURES_NUM=TIMESTEP*len(XX[0][0])\n",
    "    #print(FEATURES_NUM)\n",
    "    XX=np.reshape(XX,(-1,FEATURES_NUM))\n",
    "    return XX,YY\n",
    "def MyModel(XX,YY,spilt_size=0.3,random_key=0,n_estimators=500,max_depth=4):\n",
    "    ###############################################################################\n",
    "    # Load data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(XX,YY,test_size=spilt_size, random_state=random_key)\n",
    "    ###############################################################################\n",
    "    # Fit regression model\n",
    "    params = {'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': 2,\n",
    "              'learning_rate': 0.01, 'loss': 'ls'}\n",
    "    clf = ensemble.GradientBoostingRegressor(**params)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict  = clf.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_predict)\n",
    "    print(\"MSE: %.4f\" % mse)\n",
    "    return clf\n",
    "def error(model,x,y,name):\n",
    "    errorALL=0\n",
    "    result=[]\n",
    "    for number in range(132):\n",
    "        conti_X,conti_Y=[],[]\n",
    "        getTimeSdata2ConBox(x,y,scaler=Scaler,number=number,conti_X=conti_X,conti_Y=conti_Y,TIMESTEP=TIMESTEP,test=True)\n",
    "        XX,YY=timeS2sigle(conti_X,conti_Y,TIMESTEP=TIMESTEP)\n",
    "        y_predict=model.predict(XX)\n",
    "        result.append([number,YY.sum(),y_predict.sum()])\n",
    "        errorALL=errorALL+((YY-y_predict)**2).sum()**(1/2)\n",
    "    result=np.array(result)\n",
    "    np.savetxt(r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\"+'\\\\'+name+str(errorALL),result)\n",
    "    return errorALL,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0030\n"
     ]
    }
   ],
   "source": [
    "TIMESTEP=3    \n",
    "FRAGEMENT=0  \n",
    "NAME=\"1stNoC\"    \n",
    "Scaler = StandardScaler().fit(alldata.iloc[:,4:-3].to_numpy())    \n",
    "conti_X,conti_Y=[],[]    \n",
    "getTimeSdata2ConBox(x_Nocharing,y_Nocharing,scaler=Scaler,number=FRAGEMENT,conti_X=conti_X,conti_Y=conti_Y,TIMESTEP=TIMESTEP)    \n",
    "XX,YY=timeS2sigle(conti_X,conti_Y,TIMESTEP=TIMESTEP)    \n",
    "conti_X,conti_Y=[],[]    \n",
    "model=MyModel(XX,YY)    \n",
    "e,r=error(model,x_Nocharing,y_Nocharing,\"1stNoC\")    \n",
    "savemodel(model,NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0045\n"
     ]
    }
   ],
   "source": [
    "TIMESTEP=3\n",
    "FRAGEMENT=0\n",
    "NAME=\"ALLNOC\"\n",
    "Scaler = StandardScaler().fit(alldata.iloc[:,4:-3].to_numpy())\n",
    "conti_X,conti_Y=[],[]\n",
    "for i in range(132):\n",
    "    getTimeSdata2ConBox(x_Nocharing,y_Nocharing,scaler=Scaler,number=i,conti_X=conti_X,conti_Y=conti_Y,TIMESTEP=TIMESTEP)\n",
    "XX,YY=timeS2sigle(conti_X,conti_Y,TIMESTEP=TIMESTEP)\n",
    "conti_X,conti_Y=[],[]\n",
    "model=MyModel(XX,YY)\n",
    "e,r=error(model,x_Nocharing,y_Nocharing,NAME)\n",
    "savemodel(model,NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  562,  584],\n",
       "       [   1,  694,  733],\n",
       "       [   2,  143,  146],\n",
       "       [   3,   89,   92],\n",
       "       [   4,  100,  109],\n",
       "       [   5,    3,    3],\n",
       "       [   6,    2,    3],\n",
       "       [   7,  400,  421],\n",
       "       [   8,    8,    8],\n",
       "       [   9,    3,    4],\n",
       "       [  10,   31,   32],\n",
       "       [  11,  337,  354],\n",
       "       [  12,   19,   20],\n",
       "       [  13,    7,    7],\n",
       "       [  14,    5,    5],\n",
       "       [  15,    4,    5],\n",
       "       [  16,    7,    9],\n",
       "       [  17,    3,    4],\n",
       "       [  18,  669,  726],\n",
       "       [  19,   17,   18],\n",
       "       [  20,   16,   18],\n",
       "       [  21,  494,  496],\n",
       "       [  22,  438,  458],\n",
       "       [  23,  233,  234],\n",
       "       [  24,    6,    4],\n",
       "       [  25,    5,    4],\n",
       "       [  26,  821,  814],\n",
       "       [  27,  128,  132],\n",
       "       [  28,  397,  404],\n",
       "       [  29,   13,   12],\n",
       "       [  30,  356,  362],\n",
       "       [  31,  104,  102],\n",
       "       [  32,   11,   11],\n",
       "       [  33,  203,  201],\n",
       "       [  34,    4,    4],\n",
       "       [  35,  110,  112],\n",
       "       [  36,   91,   88],\n",
       "       [  37,    7,    7],\n",
       "       [  38,    7,    7],\n",
       "       [  39,   70,   73],\n",
       "       [  40,  516,  521],\n",
       "       [  41,   12,   13],\n",
       "       [  42,   64,   59],\n",
       "       [  43,    7,    7],\n",
       "       [  44,    6,    6],\n",
       "       [  45,    8,   10],\n",
       "       [  46,    8,    8],\n",
       "       [  47,   19,   20],\n",
       "       [  48,  771,  784],\n",
       "       [  49, 2247, 2266],\n",
       "       [  50, 2899, 2998],\n",
       "       [  51,  862,  845],\n",
       "       [  52,  455,  432],\n",
       "       [  53,    4,    3],\n",
       "       [  54,   44,   42],\n",
       "       [  55,   16,   14],\n",
       "       [  56,    2,    2],\n",
       "       [  57,    5,    6],\n",
       "       [  58,  257,  250],\n",
       "       [  59,    4,    4],\n",
       "       [  60,    5,    3],\n",
       "       [  61,  110,  110],\n",
       "       [  62,  214,  205],\n",
       "       [  63,  493,  475],\n",
       "       [  64,    6,    5],\n",
       "       [  65,    9,   11],\n",
       "       [  66,  385,  374],\n",
       "       [  67,   13,   12],\n",
       "       [  68,  468,  443],\n",
       "       [  69,    6,    6],\n",
       "       [  70,   11,   10],\n",
       "       [  71,  228,  218],\n",
       "       [  72,   52,   49],\n",
       "       [  73,  239,  224],\n",
       "       [  74,   18,   17],\n",
       "       [  75,  121,  112],\n",
       "       [  76,   29,   27],\n",
       "       [  77,   10,   10],\n",
       "       [  78,   10,   10],\n",
       "       [  79,  708,  679],\n",
       "       [  80, 1358, 1273],\n",
       "       [  81,  369,  346],\n",
       "       [  82,  188,  178],\n",
       "       [  83, 2590, 2420],\n",
       "       [  84,  827,  794],\n",
       "       [  85,   10,    9],\n",
       "       [  86,    4,    4],\n",
       "       [  87,  586,  556],\n",
       "       [  88,  417,  402],\n",
       "       [  89,   34,   33],\n",
       "       [  90,  175,  162],\n",
       "       [  91,    0,    0],\n",
       "       [  92,   63,   58],\n",
       "       [  93,    3,    4],\n",
       "       [  94,   11,   10],\n",
       "       [  95,    9,    7],\n",
       "       [  96,    5,    5],\n",
       "       [  97,    5,    6],\n",
       "       [  98,    1,    2],\n",
       "       [  99,    8,    8],\n",
       "       [ 100,  198,  189],\n",
       "       [ 101,  593,  560],\n",
       "       [ 102,  218,  198],\n",
       "       [ 103, 1180, 1075],\n",
       "       [ 104, 2550, 2456],\n",
       "       [ 105,  258,  262],\n",
       "       [ 106,    8,    8],\n",
       "       [ 107,   49,   54],\n",
       "       [ 108,    6,    6],\n",
       "       [ 109,  577,  606],\n",
       "       [ 110,    3,    3],\n",
       "       [ 111,    4,    4],\n",
       "       [ 112,  691,  715],\n",
       "       [ 113,   12,   12],\n",
       "       [ 114,    3,    3],\n",
       "       [ 115,  107,  112],\n",
       "       [ 116,   54,   53],\n",
       "       [ 117,    3,    3],\n",
       "       [ 118,  145,  151],\n",
       "       [ 119,   45,   51],\n",
       "       [ 120,  205,  216],\n",
       "       [ 121,  230,  243],\n",
       "       [ 122,  200,  205],\n",
       "       [ 123,  582,  614],\n",
       "       [ 124,  487,  509],\n",
       "       [ 125,  407,  419],\n",
       "       [ 126, 1129, 1170],\n",
       "       [ 127,  337,  350],\n",
       "       [ 128,  504,  518],\n",
       "       [ 129,  420,  473],\n",
       "       [ 130,  214,  235],\n",
       "       [ 131, 1796, 1968]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.loadtxt(r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\"+'\\\\'+\"ALLNoC286.123800192\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
