{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def savemodel(model,name):\n",
    "    path=r\"C:\\Users\\73454\\Desktop\\NCBDC 2019\\model\"+'\\\\'+name+'.pkl'\n",
    "    joblib.dump(model,path)\n",
    "def loadmodel(name):\n",
    "    path=r\"C:\\Users\\73454\\Desktop\\NCBDC 2019\\model\"+'\\\\'+name+'.pkl'\n",
    "    return joblib.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先加载数据  #本来需要加载所有数据进行归一化的，但是这里为了简化代码，直接读取归一化输入的训练数据和测试数据\n",
    "trainlist,testlist=[],[]\n",
    "alldata=pd.DataFrame()\n",
    "TestLength=7\n",
    "TrainLength=24\n",
    "for i in range(TrainLength):\n",
    "    df=pd.read_csv(r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\Data\\NormaliezdData\\SmallSizeData\\SmallSizeTrainData\"+'\\\\'+str(i)+\".csv\").iloc[:,1:]\n",
    "    trainlist.append(df)\n",
    "    alldata=pd.concat([alldata,df])\n",
    "for i in range(TestLength):\n",
    "    df=pd.read_csv(r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\Data\\NormaliezdData\\SmallSizeData\\SmallSizeTestData\"+'\\\\'+str(i)+\".csv\").iloc[:,1:]\n",
    "    testlist.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single step model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们有这么多的特征： Index(['total_voltage', 'total_current', 'soc', 'temp_max', 'temp_min',\n",
      "       'motor_voltage', 'motor_current', 'total_P', 'motor_P',\n",
      "       'tempMAXMINdiff', 'SOCgap', 'speed', 'mileage', 'milediff', 'speeddiff',\n",
      "       'milegap'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#前面数据都加载好了，现在决定一下我们的模型的输入输出\n",
    "print(\"我们有这么多的特征：\",trainlist[0].columns)\n",
    "#我们将可以输入的特征分类，分成低频特征和高频特征\n",
    "#低频特征： 'soc', 'temp_max', 'temp_min','tempMAXMINdiff','SOCgap'\n",
    "#高频特征：'speed', 'total_voltage', 'total_current', 'motor_voltage', 'motor_current', 'total_P', 'motor_P'\n",
    "#这里的speed有待争议，如果之前的速度有在模型中回归出来，那么可以放到之后时间段作为特征\n",
    "\n",
    "#这里的输出也可以有各种输出，比如timestep范围内的里程增量[milediff].sum()\n",
    "#或者回归最后一个数据距离一开始的里程的里程增量milegap\n",
    "#还可以加上速度speed，或者速度增量speeddiff\n",
    "\n",
    "#这里输出和输入的变化以及模型的调参就交给晓丹，我们这里以一个简单的为例子\n",
    "InputFeatures=['SOCgap','soc', 'total_voltage', 'total_current', 'motor_voltage', 'motor_current', 'total_P', 'motor_P']\n",
    "OutputFeatures=['milediff']\n",
    "TimeStep=3   #120*10/60=20min（）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练数据无重叠（数据量小，时间少）"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df=trainlist[5]\n",
    "import time\n",
    "time_start=time.time()\n",
    "\n",
    "trainX=[]\n",
    "trainY=[]\n",
    "lens=len(df)\n",
    "size=lens-lens%3.0\n",
    "df=df.loc[0:size-1]\n",
    "X=df.loc[:,InputFeatures].to_numpy().reshape(-1,TimeStep*len(InputFeatures))\n",
    "y=df.loc[:,OutputFeatures].to_numpy().reshape(-1,TimeStep*len(OutputFeatures))\n",
    "for index,i in enumerate(y):\n",
    "    trainX.append(X[index])\n",
    "    trainY.append(i.sum())\n",
    "\n",
    "time_end=time.time()\n",
    "print('totally cost',time_end-time_start)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import time\n",
    "time_start=time.time()\n",
    "\n",
    "trainX=[]\n",
    "trainY=[]\n",
    "for df in trainlist:\n",
    "    lens=len(df)\n",
    "    size=lens-lens%3.0\n",
    "    df=df.loc[0:size-1]\n",
    "    X=df.loc[:,InputFeatures].to_numpy().reshape(-1,TimeStep*len(InputFeatures))\n",
    "    y=df.loc[:,OutputFeatures].to_numpy().reshape(-1,TimeStep*len(OutputFeatures))\n",
    "    for index,i in enumerate(y):\n",
    "        trainX.append(X[index])\n",
    "        trainY.append(i.sum())\n",
    "        \n",
    "time_end=time.time()\n",
    "print('totally cost',time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练数据有重叠（数据量大，时间少）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totally cost 0.026901721954345703\n"
     ]
    }
   ],
   "source": [
    "df=trainlist[5]\n",
    "import time\n",
    "time_start=time.time()\n",
    "\n",
    "trainX=[]\n",
    "trainY=[]\n",
    "lens=len(df)\n",
    "X=df.loc[:,InputFeatures].to_numpy()\n",
    "y=df.loc[:,OutputFeatures].to_numpy()\n",
    "for i in range(lens-TimeStep):\n",
    "    trainX.append(X[i:i+TimeStep].reshape(TimeStep*len(InputFeatures)))\n",
    "    trainY.append(y[i:i+TimeStep].sum())\n",
    "    \n",
    "time_end=time.time()\n",
    "print('totally cost',time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totally cost 0.5046162605285645\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time_start=time.time()\n",
    "\n",
    "trainX=[]\n",
    "trainY=[]\n",
    "for df in trainlist:\n",
    "    lens=len(df)\n",
    "    X=df.loc[:,InputFeatures].to_numpy()\n",
    "    y=df.loc[:,OutputFeatures].to_numpy()\n",
    "    for i in range(lens-TimeStep):\n",
    "        trainX.append(X[i:i+TimeStep].reshape(TimeStep*len(InputFeatures)))\n",
    "        trainY.append(y[i:i+TimeStep].sum())\n",
    "        \n",
    "time_end=time.time()\n",
    "print('totally cost',time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MyModel(Normalized_X,Normalized_Y,spilt_size=0.1,random_key=0,n_estimators=500,max_depth=4):\n",
    "    ###############################################################################\n",
    "    # Load data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(Normalized_X,Normalized_Y,test_size=spilt_size, random_state=random_key)\n",
    "    ###############################################################################\n",
    "    # Fit regression model\n",
    "    params = {'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': 2,\n",
    "              'learning_rate': 0.01, 'loss': 'ls'}\n",
    "    clf = ensemble.GradientBoostingRegressor(**params)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict  = clf.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_predict)\n",
    "    print(\"MSE: %.4f\" % mse)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0041\n"
     ]
    }
   ],
   "source": [
    "model=MyModel(trainX,trainY,n_estimators=500,max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.01, loss='ls', max_depth=4,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试方法：先将测试集数据转换成输入，然后得到测试集输出，和测试集真实里程差作比较（最后的里程差）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 无重叠结果测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.19823872554943 83.79999999999562\n",
      "0 11.548026435853583\n",
      "113.97165679664207 114.39999999999418\n",
      "1 0.18347789985795027\n",
      "126.45998501872907 121.0\n",
      "2 29.811436404745898\n",
      "91.16745291170635 96.59999999999854\n",
      "3 29.51256786651202\n",
      "118.66641181293528 117.80000000000292\n",
      "4 0.750669429588731\n",
      "133.268039103974 121.30000000000292\n",
      "5 143.23395999418054\n",
      "112.621457259893 115.5\n",
      "6 8.28600830662268\n"
     ]
    }
   ],
   "source": [
    "Result = 0\n",
    "for index,df in enumerate(testlist):\n",
    "    lens=len(df)\n",
    "    size=lens-lens%3.0\n",
    "    X=df.loc[0:size-1].loc[:,InputFeatures].to_numpy().reshape(-1,TimeStep*len(InputFeatures))\n",
    "    result=model.predict(X).sum()\n",
    "    true=df.iloc[-1].milegap\n",
    "    print(result,true)\n",
    "    result=(true-result)**2\n",
    "    print(index,result)\n",
    "    Result=Result+result\n",
    "Result=Result**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.944100720262876"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重叠结果测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.94298925120984 83.79999999999562\n",
      "0 9.878381433248107\n",
      "114.2751458602969 114.39999999999418\n",
      "1 0.01558855619954713\n",
      "125.83932904230181 121.0\n",
      "2 23.419105579665782\n",
      "91.19687529103517 96.59999999999854\n",
      "3 29.193756620610557\n",
      "119.07992626524083 117.80000000000292\n",
      "4 1.6382112444458499\n",
      "131.9059938030396 121.30000000000292\n",
      "5 112.48710455005221\n",
      "114.02578277197212 115.5\n",
      "6 2.173316435414213\n"
     ]
    }
   ],
   "source": [
    "Result2 = 0\n",
    "for index,df in enumerate(testlist):\n",
    "    trainX=[]\n",
    "    lens=len(df)\n",
    "    X=df.loc[:,InputFeatures].to_numpy()\n",
    "    y=df.loc[:,OutputFeatures].to_numpy()\n",
    "    for i in range(lens-TimeStep):\n",
    "        trainX.append(X[i:i+TimeStep].reshape(TimeStep*len(InputFeatures)))\n",
    "    result=model.predict(trainX).sum()/TimeStep\n",
    "    true=df.iloc[-1].milegap\n",
    "    print(result,true)\n",
    "    result=(true-result)**2\n",
    "    print(index,result)\n",
    "    Result2=Result2+result\n",
    "Result2=Result2**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.37181604792843"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=testlist[0]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得到提交数据结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "duelist=[]\n",
    "path = lambda car,number:r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\Data\\Test\\NormalizedClearTestData\\car\"+str(car)+\"frag\"+str(number)+'.csv'\n",
    "for i in range(15,30):\n",
    "    for j in range(100,120):\n",
    "        duelist.append(pd.read_csv(path(i,j)).iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#使用不重叠的方法得到的提交数据结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResultList=[]\n",
    "for index,df in enumerate(duelist):\n",
    "    lens=len(df)\n",
    "    size=lens-lens%3.0\n",
    "    X=df.loc[0:size-1].loc[:,InputFeatures].to_numpy().reshape(-1,TimeStep*len(InputFeatures))\n",
    "    result=model.predict(X).sum()\n",
    "    ResultList.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#使用重叠方法得到的提交数据结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result2List = []\n",
    "for index,df in enumerate(duelist):\n",
    "    trainX=[]\n",
    "    lens=len(df)\n",
    "    X=df.loc[:,InputFeatures].to_numpy()\n",
    "    for i in range(lens-TimeStep):\n",
    "        trainX.append(X[i:i+TimeStep].reshape(TimeStep*len(InputFeatures)))\n",
    "    result=model.predict(trainX).sum()/TimeStep\n",
    "    Result2List.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs=pd.DataFrame(ResultList,columns=['milegap'])\n",
    "rs.to_csv(r\"C:\\Users\\73454\\Desktop\\NCBDC 2019\\Result\\Submit2.csv\")\n",
    "savemodel(model,\"Day2\")\n",
    "model=loadmodel(\"Day2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
