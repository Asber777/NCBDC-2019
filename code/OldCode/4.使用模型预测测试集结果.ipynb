{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:115: UserWarning: Numpy 1.13.3 or above is required for this version of scipy (detected version 1.13.1)\n",
      "  UserWarning)\n",
      "D:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def savemodel(model,name):\n",
    "    path=r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\"+'\\\\'+name+'.pkl'\n",
    "    joblib.dump(model,path)\n",
    "def loadmodel(name):\n",
    "    path=r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\"+'\\\\'+name+'.pkl'\n",
    "    return joblib.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "alldata=pd.DataFrame()\n",
    "LEN_DATASET=132\n",
    "traindata=[]\n",
    "#这里读取的是有带充电数据的\n",
    "for number in range(LEN_DATASET):\n",
    "    df=pd.read_csv(r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\continueTimedata\"+'\\\\'+str(number)+\".csv\")\n",
    "    alldata=pd.concat([alldata,df])\n",
    "    traindata.append(df)\n",
    "testdata=[]\n",
    "for number in range(100):\n",
    "    df=pd.read_csv(r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\clearTestData\"+'\\\\'+str(number)+\".csv\").iloc[:,2:10]\n",
    "    testdata.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TIMESTEP=3    \n",
    "scaler = StandardScaler().fit(alldata.iloc[:,4:-3].to_numpy())    \n",
    "dataX=testdata[0].iloc[:,:-1]\n",
    "conti_X=[]\n",
    "#归一化\n",
    "X=scaler.transform(dataX.to_numpy())\n",
    "#分成三个数据的array集合\n",
    "datasize=len(X)\n",
    "for i in range(0,datasize-TIMESTEP+1,TIMESTEP):\n",
    "    conti_X.append(X[i:i+TIMESTEP])\n",
    "XX=np.array(conti_X)\n",
    "FEATURES_NUM=TIMESTEP*len(XX[0][0])\n",
    "XX=np.reshape(XX,(-1,FEATURES_NUM))\n",
    "model=loadmodel(\"ALLNOC\")\n",
    "y_predict=model.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer=[]\n",
    "for i in y_predict:\n",
    "    answer.append(0)\n",
    "    answer.append(0)\n",
    "    answer.append(i)\n",
    "dataX['milediff']=answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindataWithoutCharging=[]\n",
    "LEN_DATASET=132\n",
    "LEN_NCDATA=[]\n",
    "for number in range(LEN_DATASET):\n",
    "    df=pd.read_csv(r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\continueTimedataWithoutCharging\"+'\\\\'+str(number)+\".csv\")\n",
    "    traindataWithoutCharging.append(df)\n",
    "    LEN_NCDATA.append(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEP=3    \n",
    "scaler = StandardScaler().fit(alldata.iloc[:,4:-3].to_numpy())    \n",
    "data=traindataWithoutCharging[0]\n",
    "dataX=data.iloc[:,5:-3]\n",
    "dataY=data.iloc[:,-1]\n",
    "conti_X=[]\n",
    "conti_Y=[]\n",
    "#归一化\n",
    "X=scaler.transform(dataX.to_numpy())\n",
    "Y=dataY\n",
    "#分成三个数据的array集合\n",
    "datasize=len(X)\n",
    "for i in range(0,datasize-TIMESTEP+1,TIMESTEP):\n",
    "    conti_X.append(X[i:i+TIMESTEP])\n",
    "    conti_Y.append(Y[i:i+TIMESTEP].sum())\n",
    "XX=np.array(conti_X)\n",
    "FEATURES_NUM=TIMESTEP*len(XX[0][0])\n",
    "XX=np.reshape(XX,(-1,FEATURES_NUM))\n",
    "model=loadmodel(\"ALLNOC\")\n",
    "y_predict=model.predict(XX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
