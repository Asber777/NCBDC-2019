{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savemodel(model,name):\n",
    "    path=r\"C:\\Users\\73454\\Desktop\\NCBDC 2019\\model\"+'\\\\'+name+'.pkl'\n",
    "    joblib.dump(model,path)\n",
    "def loadmodel(name):\n",
    "    path=r\"C:\\Users\\73454\\Desktop\\NCBDC 2019\\model\"+'\\\\'+name+'.pkl'\n",
    "    return joblib.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先加载数据  #本来需要加载所有数据进行归一化的，但是这里为了简化代码，直接读取归一化输入的训练数据和测试数据\n",
    "trainlist,testlist=[],[]\n",
    "alldata=pd.DataFrame()\n",
    "TestLength=7\n",
    "TrainLength=30\n",
    "for i in range(TrainLength):\n",
    "    df=pd.read_csv(r\"C:\\Users\\73454\\Desktop\\NCBDC 2019\\SmallSizeTrainData\"+'\\\\'+str(i)+\".csv\").iloc[:,1:]\n",
    "    trainlist.append(df)\n",
    "    alldata=pd.concat([alldata,df])\n",
    "for i in range(TestLength):\n",
    "    df=pd.read_csv(r\"C:\\Users\\73454\\Desktop\\NCBDC 2019\\SmallSizeTestData\"+'\\\\'+str(i)+\".csv\").iloc[:,1:]\n",
    "    testlist.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single step model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们有这么多的特征： Index(['total_voltage', 'total_current', 'soc', 'temp_max', 'temp_min',\n",
      "       'motor_voltage', 'motor_current', 'total_P', 'motor_P',\n",
      "       'tempMAXMINdiff', 'SOCgap', 'speed', 'mileage', 'milediff', 'speeddiff',\n",
      "       'milegap'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#前面数据都加载好了，现在决定一下我们的模型的输入输出\n",
    "print(\"我们有这么多的特征：\",trainlist[0].columns)\n",
    "#我们将可以输入的特征分类，分成低频特征和高频特征\n",
    "#低频特征： 'soc', 'temp_max', 'temp_min','tempMAXMINdiff','SOCgap'\n",
    "#高频特征：'speed', 'total_voltage', 'total_current', 'motor_voltage', 'motor_current', 'total_P', 'motor_P'\n",
    "#这里的speed有待争议，如果之前的速度有在模型中回归出来，那么可以放到之后时间段作为特征\n",
    "\n",
    "#这里的输出也可以有各种输出，比如timestep范围内的里程增量[milediff].sum()\n",
    "#或者回归最后一个数据距离一开始的里程的里程增量milegap\n",
    "#还可以加上速度speed，或者速度增量speeddiff\n",
    "\n",
    "#这里输出和输入的变化以及模型的调参就交给晓丹，我们这里以一个简单的为例子\n",
    "InputFeatures=['SOCgap','soc', 'total_voltage', 'total_current', 'motor_voltage', 'motor_current', 'total_P', 'motor_P']\n",
    "OutputFeatures=['milediff']\n",
    "TimeStep=36   #120*10/60=20min（）\n",
    "AvrgTime=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个功能主要是把一个df转换成 timestep为一组的df的list 注意 有一些数据集其数据个数<=timestep 会导致输出为[]\n",
    "def df2Timedf(df,inputFeature,outputFeature, timestep):\n",
    "    end_index=len(df)\n",
    "    data=[]\n",
    "    for i in range(timestep,end_index):\n",
    "        indices=range(i-timestep,i)\n",
    "        data.append(df.loc[indices,inputFeature+outputFeature])\n",
    "    if data!=[]:#数据集其数据个数<=timestep 会导致输出为[] 传递None\n",
    "        return data\n",
    "    else:\n",
    "        return \n",
    "#此处是将输入改成（个数，timestep,features）的array,输出（可以改的）是20mins的milediff的和\n",
    "# 可以满足RNN的需要了\n",
    "def Timedf2RNNdata(Timedf,inputFeature,outputFeature):#此函数未处理None Timedf情况\n",
    "    Xset,Yset=[],[]\n",
    "    for df in Timedf:\n",
    "        X=df.loc[:,inputFeature].to_numpy()\n",
    "        Y=df.loc[:,outputFeature].to_numpy()\n",
    "        Xset.append(X)\n",
    "        Yset.append(Y.sum())#注意此处.sum()\n",
    "    Xset=np.array(Xset)\n",
    "    Yset=np.array(Yset)\n",
    "    Yset=np.reshape(Yset,(-1,))\n",
    "    return Xset,Yset\n",
    "#下面是我们的机器学习方法的数据转换，需要将（None，120，8）的数据变成（None，10*8）的数据\n",
    "#也是就说我们每12个数据就需要变成一个数据（取平均）avrgTime=12 (120/12=10)\n",
    "def Timedf2GDBT(Timedf,inputFeature,outputFeatures,avrgTime):\n",
    "    if(Timedf==None):\n",
    "        print(\"Timedf contain nothing\")\n",
    "        return None,None   #如果timedf为None 输出数据也是None，None\n",
    "    Xset,Yset=[],np.array([])\n",
    "    length=len(Timedf[0])\n",
    "    for df in Timedf:\n",
    "        X=df.loc[:,inputFeature]\n",
    "        Y=df.loc[:,outputFeatures]\n",
    "        Xc=np.array([])\n",
    "        for i in range(int(length/avrgTime)):#这里就是 range(10)\n",
    "            begin_index=i*avrgTime\n",
    "            end_index=(i+1)*avrgTime\n",
    "            dataX=np.array(X[begin_index:end_index].mean())\n",
    "            Xc=np.append(Xc,dataX)\n",
    "        Xset.append(Xc)\n",
    "        Yset=np.append(Yset,Y.sum()[0])\n",
    "    Xset=np.array(Xset)\n",
    "    return Xset,Yset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个是读取一个训练集的代码"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df=trainlist[3]\n",
    "Timedf=df2Timedf(df,InputFeatures,OutputFeatures,TimeStep)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Xset,Yset=Timedf2GDBT(Timedf,InputFeatures,OutputFeatures,avrgTime=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个是读取所有训练集的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dataset is already\n",
      "1 dataset is already\n",
      "2 dataset is already\n",
      "3 dataset is already\n",
      "4 dataset is already\n",
      "5 dataset is already\n",
      "6 dataset is already\n",
      "7 dataset is already\n",
      "8 dataset is already\n",
      "9 dataset is already\n",
      "10 dataset is already\n",
      "11 dataset is already\n",
      "12 dataset is already\n",
      "13 dataset is already\n",
      "14 dataset is already\n",
      "15 dataset is already\n",
      "16 dataset is already\n",
      "17 dataset is already\n",
      "18 dataset is already\n",
      "19 dataset is already\n",
      "20 dataset is already\n",
      "21 dataset is already\n",
      "22 dataset is already\n",
      "23 dataset is already\n",
      "24 dataset is already\n",
      "25 dataset is already\n",
      "26 dataset is already\n",
      "27 dataset is already\n",
      "28 dataset is already\n",
      "29 dataset is already\n"
     ]
    }
   ],
   "source": [
    "#上面我们定义过 TimeStep=120\n",
    "SIZE=int(TimeStep/AvrgTime*len(InputFeatures))\n",
    "trainX,trainY=np.empty((1,SIZE)),np.array([])\n",
    "for index,df in enumerate(trainlist):\n",
    "    if(len(df)<=TimeStep):\n",
    "        continue\n",
    "    Timedf=df2Timedf(df,InputFeatures,OutputFeatures,TimeStep)\n",
    "    Xset,Yset=Timedf2GDBT(Timedf,InputFeatures,OutputFeatures,avrgTime=AvrgTime)\n",
    "    trainX=np.vstack((trainX,Xset))\n",
    "    trainY=np.append(trainY,Yset)\n",
    "    print(index,\"dataset is already\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=trainX[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel(Normalized_X,Normalized_Y,spilt_size=0.1,random_key=0,n_estimators=500,max_depth=4):\n",
    "    ###############################################################################\n",
    "    # Load data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(Normalized_X,Normalized_Y,test_size=spilt_size, random_state=random_key)\n",
    "    ###############################################################################\n",
    "    # Fit regression model\n",
    "    params = {'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': 2,\n",
    "              'learning_rate': 0.01, 'loss': 'ls'}\n",
    "    clf = ensemble.GradientBoostingRegressor(**params)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict  = clf.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_predict)\n",
    "    print(\"MSE: %.4f\" % mse)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [59141, 59143]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-9b065029caf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMyModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-876ad6571850>\u001b[0m in \u001b[0;36mMyModel\u001b[1;34m(Normalized_X, Normalized_Y, spilt_size, random_key, n_estimators, max_depth)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m###############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNormalized_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNormalized_Y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspilt_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m###############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Fit regression model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2029\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2031\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2033\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 204\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [59141, 59143]"
     ]
    }
   ],
   "source": [
    "model=MyModel(trainX,trainY,n_estimators=500,max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.01, loss='ls', max_depth=4, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=500, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试方法：先将测试集数据转换成输入，然后得到测试集输出，和测试集真实里程差作比较（最后的里程差）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 无重叠结果测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.65163144204081 83.79999999999562\n",
      "0 17.208961692628076\n",
      "111.13816113955897 114.39999999999418\n",
      "1 10.639592751445235\n",
      "124.88431366212289 121.0\n",
      "2 15.087892625754554\n",
      "85.12547915044934 96.59999999999854\n",
      "3 131.66462872673947\n",
      "114.49931498739954 117.80000000000292\n",
      "4 10.894521552424582\n",
      "132.20219728916376 121.30000000000292\n",
      "5 118.85790573178593\n",
      "116.72029213821445 115.5\n",
      "6 1.4891129025879863\n"
     ]
    }
   ],
   "source": [
    "Result = 0\n",
    "for index,df in enumerate(testlist):\n",
    "    Timedf=df2Timedf(df,InputFeatures,OutputFeatures,TimeStep)\n",
    "    Xset,Yset=Timedf2GDBT(Timedf,InputFeatures,OutputFeatures,avrgTime=AvrgTime)\n",
    "    result=0\n",
    "    for Index,x in enumerate(Xset):\n",
    "        if(Index%TimeStep==0):\n",
    "            a=model.predict(x.reshape(-1, SIZE))[0]\n",
    "            result=result+a\n",
    "    print(result,df.iloc[-1].milegap)\n",
    "    result=(df.iloc[-1].milegap-result)**2\n",
    "    print(index,result)\n",
    "    Result=Result+result\n",
    "Result=Result**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.488356583263215"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重叠结果测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.94513072184273 83.79999999999562\n",
      "0 34.279494264258545\n",
      "109.07676156051643 114.39999999999418\n",
      "1 28.336867483533492\n",
      "125.83786905058209 121.0\n",
      "2 23.40497695058001\n",
      "85.11476600934704 96.59999999999854\n",
      "3 131.91059982001678\n",
      "111.95320857820772 117.80000000000292\n",
      "4 34.18496992997797\n",
      "131.82246749070165 121.30000000000292\n",
      "5 110.72232209281164\n",
      "118.5548830211754 115.5\n",
      "6 9.332310273065737\n"
     ]
    }
   ],
   "source": [
    "Result2 = 0\n",
    "for index,df in enumerate(testlist):\n",
    "    Timedf=df2Timedf(df,InputFeatures,OutputFeatures,TimeStep)\n",
    "    Xset,Yset=Timedf2GDBT(Timedf,InputFeatures,OutputFeatures,avrgTime=AvrgTime)\n",
    "    result=0\n",
    "    for Index,x in enumerate(Xset):\n",
    "        a=model.predict(x.reshape(-1, SIZE))[0]\n",
    "        result=result+a\n",
    "    result=result/TimeStep\n",
    "    print(result,df.iloc[-1].milegap)\n",
    "    result=(df.iloc[-1].milegap-result)**2\n",
    "    print(index,result)\n",
    "    Result2=Result2+result\n",
    "Result2=Result2**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.29174799789392"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=testlist[0]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def padding(df):\n",
    "    lens=len(df)\n",
    "    print(lens)\n",
    "    foredata=df.loc[0]\n",
    "    foredata.total_current=-0.292503883\n",
    "    foredata.motor_current=-0.3233341680\n",
    "    foredata.speed=0\n",
    "    foredf=pd.DataFrame(columns=df.columns)\n",
    "    for number in range(0,TimeStep):\n",
    "        foredf.loc[number]=foredata\n",
    "    backdf=pd.DataFrame(columns=df.columns)\n",
    "    backdata=df.iloc[lens-1]\n",
    "    backdata.total_current=-0.292503883\n",
    "    backdata.motor_current=-0.3233341680\n",
    "    backdata.speed=0\n",
    "    for number in range(0,TimeStep):\n",
    "        backdf.loc[number]=backdata\n",
    "    mydf=pd.DataFrame(columns=df.columns)\n",
    "    return pd.concat([foredf,df,backdf],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1683\n",
      "81.26179565178364 83.79999999999562\n",
      "0 6.442481313282187\n",
      "2681\n",
      "110.10780309609486 114.39999999999418\n",
      "1 18.422954261842943\n",
      "2857\n",
      "127.62805947314246 121.0\n",
      "2 43.93117237951347\n",
      "1556\n",
      "85.93983069594968 96.59999999999854\n",
      "3 113.63920959098564\n",
      "2704\n",
      "113.99672230947188 117.80000000000292\n",
      "4 14.464921191291175\n",
      "2685\n",
      "133.37990692775668 121.30000000000292\n",
      "5 145.92415138319313\n",
      "1759\n",
      "120.37308637897415 115.5\n",
      "6 23.7469708569434\n"
     ]
    }
   ],
   "source": [
    "Result3=0\n",
    "for index,Df in enumerate(testlist):\n",
    "    df=padding(Df)\n",
    "    Timedf=df2Timedf(df,InputFeatures,OutputFeatures,TimeStep)\n",
    "    Xset,Yset=Timedf2GDBT(Timedf,InputFeatures,OutputFeatures,avrgTime=AvrgTime)\n",
    "    result=0\n",
    "    for Index,x in enumerate(Xset):\n",
    "        a=model.predict(x.reshape(-1, SIZE))[0]\n",
    "        result=result+a\n",
    "    result=result/TimeStep\n",
    "    print(result,df.iloc[-1].milegap)\n",
    "    result=(df.iloc[-1].milegap-result)**2\n",
    "    print(index,result)\n",
    "    Result3=Result3+result\n",
    "Result3=Result3**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.14606646225412"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result3 #22.9730"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Result3=0\n",
    "\n",
    "    Timedf=df2Timedf(df,InputFeatures,OutputFeatures,TimeStep)\n",
    "    Xset,Yset=Timedf2GDBT(Timedf,InputFeatures,OutputFeatures,avrgTime=12)\n",
    "    result=0\n",
    "    for Index,x in enumerate(Xset):\n",
    "        a=model.predict(x.reshape(-1, 80))[0]\n",
    "        result=result+a\n",
    "    result=result/TimeStep\n",
    "    result=(df.iloc[-1].milegap-result)**2\n",
    "    print(index,result)\n",
    "    Result3=Result3+result\n",
    "Result3=Result3**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "duelist=[]\n",
    "DueLength=100\n",
    "for i in range(DueLength):\n",
    "    df=pd.read_csv(r\"C:\\Users\\73454\\Desktop\\NCBDC 2019\\NormalizedDueTestData\"+'\\\\'+str(i)+\".csv\").iloc[:,1:]\n",
    "    duelist.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 60.80752313061299\n",
      "1 83.2567004033096\n",
      "2 44.482775931923676\n",
      "3 82.06783160677098\n",
      "4 26.69214797109212\n",
      "5 70.21281861687346\n",
      "6 91.58300463495085\n",
      "7 98.45853586254395\n",
      "8 97.40102124508672\n"
     ]
    }
   ],
   "source": [
    "ResultList=[]\n",
    "for index,df in enumerate(duelist[91:]):\n",
    "    Timedf=df2Timedf(df,InputFeatures,OutputFeatures,TimeStep)\n",
    "    Xset,Yset=Timedf2GDBT(Timedf,InputFeatures,OutputFeatures,avrgTime=AvrgTime)\n",
    "    result=0\n",
    "    for Index,x in enumerate(Xset):\n",
    "        if(Index%TimeStep==0):\n",
    "            a=model.predict(x.reshape(-1, SIZE))[0]\n",
    "            result=result+a\n",
    "    print(index,result)\n",
    "    ResultList.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs=pd.DataFrame(ResultList,columns=['milegap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.to_csv(r\"C:\\Users\\73454\\Desktop\\NCBDC 2019\\Result\\Submit2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemodel(model,\"Day2\")\n",
    "model=loadmodel(\"Day2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下面是之前写的代码"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TIMESTEP=3    \n",
    "FRAGEMENT=0  \n",
    "NAME=\"1stNoC\"    \n",
    "Scaler = StandardScaler().fit(alldata.iloc[:,4:-3].to_numpy())    \n",
    "conti_X,conti_Y=[],[]    \n",
    "getTimeSdata2ConBox(x_Nocharing,y_Nocharing,scaler=Scaler,number=FRAGEMENT,conti_X=conti_X,conti_Y=conti_Y,TIMESTEP=TIMESTEP)    \n",
    "XX,YY=timeS2sigle(conti_X,conti_Y,TIMESTEP=TIMESTEP)    \n",
    "conti_X,conti_Y=[],[]    \n",
    "model=MyModel(XX,YY)    \n",
    "e,r=error(model,x_Nocharing,y_Nocharing,\"1stNoC\")    \n",
    "savemodel(model,NAME)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TIMESTEP=3\n",
    "FRAGEMENT=0\n",
    "NAME=\"ALLNOC\"\n",
    "Scaler = StandardScaler().fit(alldata.iloc[:,4:-3].to_numpy())\n",
    "conti_X,conti_Y=[],[]\n",
    "for i in range(132):\n",
    "    getTimeSdata2ConBox(x_Nocharing,y_Nocharing,scaler=Scaler,number=i,conti_X=conti_X,conti_Y=conti_Y,TIMESTEP=TIMESTEP)\n",
    "XX,YY=timeS2sigle(conti_X,conti_Y,TIMESTEP=TIMESTEP)\n",
    "conti_X,conti_Y=[],[]\n",
    "model=MyModel(XX,YY)\n",
    "e,r=error(model,x_Nocharing,y_Nocharing,NAME)\n",
    "savemodel(model,NAME)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.loadtxt(r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\"+'\\\\'+\"ALLNoC286.123800192\").astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
