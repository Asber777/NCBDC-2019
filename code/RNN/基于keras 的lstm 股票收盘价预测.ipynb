{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/luoganttcc/article/details/79046870"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:115: UserWarning: Numpy 1.13.3 or above is required for this version of scipy (detected version 1.13.1)\n",
      "  UserWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\cbook.py:136: MatplotlibDeprecationWarning: The finance module has been deprecated in mpl 2.0 and will be removed in mpl 2.2. Please use the module mpl_finance instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.dates import DateFormatter, WeekdayLocator, DayLocator, MONDAY,YEARLY\n",
    "from matplotlib.finance import quotes_historical_yahoo_ohlc, candlestick_ohlc\n",
    "#import matplotlib\n",
    "import tushare as ts\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import date2num\n",
    "import datetime\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from numpy import row_stack,column_stack\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df=ts.get_hist_data('601857',start='2016-06-15',end='2018-01-12')\n",
    "dd=df[['open','high','low','close']]\n",
    "\n",
    "#print(dd.values.shape[0])\n",
    "\n",
    "dd1=dd .sort_index()\n",
    "\n",
    "dd2=dd1.values.flatten()\n",
    "\n",
    "dd3=pandas.DataFrame(dd1['close'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(df, sequence_length=10, split=0.8):\n",
    "    \n",
    "    #df = pd.read_csv(file_name, sep=',', usecols=[1])\n",
    "    #data_all = np.array(df).astype(float)\n",
    "    \n",
    "    data_all = np.array(df).astype(float)\n",
    "    scaler = MinMaxScaler()\n",
    "    data_all = scaler.fit_transform(data_all)\n",
    "    data = []\n",
    "    for i in range(len(data_all) - sequence_length - 1):\n",
    "        data.append(data_all[i: i + sequence_length + 1])\n",
    "    reshaped_data = np.array(data).astype('float64')\n",
    "    #np.random.shuffle(reshaped_data)\n",
    "    # 对x进行统一归一化，而y则不归一化\n",
    "    x = reshaped_data[:, :-1]\n",
    "    y = reshaped_data[:, -1]\n",
    "    split_boundary = int(reshaped_data.shape[0] * split)\n",
    "    train_x = x[: split_boundary]\n",
    "    test_x = x[split_boundary:]\n",
    "\n",
    "    train_y = y[: split_boundary]\n",
    "    test_y = y[split_boundary:]\n",
    "\n",
    "    return train_x, train_y, test_x, test_y, scaler\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    # input_dim是输入的train_x的最后一个维度，train_x的维度为(n_samples, time_steps, input_dim)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(input_dim=1, output_dim=6, return_sequences=True))\n",
    "    #model.add(LSTM(6, input_dim=1, return_sequences=True))\n",
    "    #model.add(LSTM(6, input_shape=(None, 1),return_sequences=True))\n",
    "    \n",
    "    \"\"\"\n",
    "    #model.add(LSTM(input_dim=1, output_dim=6,input_length=10, return_sequences=True))\n",
    "    #model.add(LSTM(6, input_dim=1, input_length=10, return_sequences=True))\n",
    "    model.add(LSTM(6, input_shape=(10, 1),return_sequences=True))\n",
    "    \"\"\"\n",
    "    print(model.layers)\n",
    "    #model.add(LSTM(100, return_sequences=True))\n",
    "    #model.add(LSTM(100, return_sequences=True))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dense(output_dim=1))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='rmsprop')\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(train_x, train_y, test_x, test_y):\n",
    "    model = build_model()\n",
    "\n",
    "    try:\n",
    "        model.fit(train_x, train_y, batch_size=512, nb_epoch=300, validation_split=0.1)\n",
    "        predict = model.predict(test_x)\n",
    "        predict = np.reshape(predict, (predict.size, ))\n",
    "    except KeyboardInterrupt:\n",
    "        print(predict)\n",
    "        print(test_y)\n",
    "    print(predict)\n",
    "    print(test_y)\n",
    "    try:\n",
    "        fig = plt.figure(1)\n",
    "        plt.plot(predict, 'r:')\n",
    "        plt.plot(test_y, 'g-')\n",
    "        plt.legend(['predict', 'true'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return predict, test_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 10, 1), (140, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 10, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#train_x, train_y, test_x, test_y, scaler = load_data('international-airline-passengers.csv')\n",
    "train_x, train_y, test_x, test_y, scaler =load_data(dd3, sequence_length=10, split=0.8)\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))\n",
    "train_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_y, test_y = train_model(train_x, train_y, test_x, test_y)\n",
    "predict_y = scaler.inverse_transform([[i] for i in predict_y])\n",
    "test_y = scaler.inverse_transform(test_y)\n",
    "fig2 = plt.figure(2)\n",
    "plt.plot(predict_y, 'g:')\n",
    "plt.plot(test_y, 'r-')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
