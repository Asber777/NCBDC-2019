{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get train data (use for train & test )\n",
    "path = lambda number:r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\Data\\NormaliezdData\\NormlizedTrainData\"+'\\\\'+str(number)+\".csv\"\n",
    "traindflist=[]\n",
    "DFSIZE=158\n",
    "for i in range(DFSIZE):\n",
    "    df=pd.read_csv( path(i) ).iloc[:,1:]\n",
    "    traindflist.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get test data\n",
    "path = lambda number:r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\Data\\NormaliezdData\\NormilizedTestData\"+'\\\\'+str(number)+\".csv\"\n",
    "testdflist=[]\n",
    "DFSIZE=52\n",
    "for i in range(DFSIZE):\n",
    "    df=pd.read_csv( path(i) ).iloc[:,1:]\n",
    "    testdflist.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputfeature=['total_voltage', 'total_current', 'soc', 'temp_max', 'temp_min',\n",
    "       'motor_voltage', 'motor_current', 'total_P', 'motor_P',\n",
    "       'tempMAXMINdiff', 'SOCgap']\n",
    "outputfeature=['milediff']\n",
    "TimeStep=24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 带TimeStep的LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNX=[]\n",
    "RNNY=[]\n",
    "for df in traindflist:\n",
    "    X=df.loc[:,inputfeature].to_numpy()\n",
    "    y=df.loc[:,outputfeature].to_numpy()\n",
    "    lens=len(df)\n",
    "    for index in range(TimeStep,lens):\n",
    "        RNNX.append(X[index-TimeStep:index])\n",
    "        RNNY.append(y[index-TimeStep:index].cumsum())\n",
    "RNNX=np.array(RNNX)\n",
    "RNNY=np.array(RNNY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分为测试集和训练集（可没有此步 ，因为我们有选择测试数据集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #这里是引用了交叉验证\n",
    "X_train,X_test, y_train, y_test = train_test_split(RNNX,RNNY,test_size = 0.1,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37280, 30, 11) (37280, 30, 1) (9321, 30, 11) (9321, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape , y_train.shape , X_test.shape , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=RNNX\n",
    "y_train=RNNY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , BatchNormalization , Dropout , Activation\n",
    "from keras.layers import LSTM , GRU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.optimizers import Adam , SGD , RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lr_reduce 设置损失不减则降低学习率\n",
    "### checkPoint设置保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "PathName=r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\\RNN\"\n",
    "filepath=PathName+\"\\\\2ndl_weights.hdf5\"\n",
    "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, epsilon=0.0001, patience=1, verbose=1)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置模型输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE=100\n",
    "BATCH_SIZE=25\n",
    "train_data_single = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_single = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "val_data_single = val_data_single.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  设置模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape=X_train.shape[-2:]\n",
    "\n",
    "single_step_model = tf.keras.models.Sequential()\n",
    "\n",
    "single_step_model.add(tf.keras.layers.LSTM(32,\n",
    "                                           input_shape=input_shape,return_sequences=True))\n",
    "single_step_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "single_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
    "#single_step_model.compile(loss='mean_squared_error', optimizer=Adam(lr = 0.001) , metrics = ['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 500 steps, validate for 50 steps\n",
      "Epoch 1/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.2218\n",
      "Epoch 00001: val_loss improved from -inf to 0.34171, saving model to C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\\RNN\\2ndl_weights.hdf5\n",
      "500/500 [==============================] - 26s 51ms/step - loss: 0.2219 - val_loss: 0.3417\n",
      "Epoch 2/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.2132\n",
      "Epoch 00002: val_loss improved from 0.34171 to 0.46561, saving model to C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\\RNN\\2ndl_weights.hdf5\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "500/500 [==============================] - 6s 11ms/step - loss: 0.2134 - val_loss: 0.4656\n",
      "Epoch 3/30\n",
      "496/500 [============================>.] - ETA: 0s - loss: 0.2259\n",
      "Epoch 00003: val_loss did not improve from 0.46561\n",
      "500/500 [==============================] - 6s 11ms/step - loss: 0.2246 - val_loss: 0.2131\n",
      "Epoch 4/30\n",
      "496/500 [============================>.] - ETA: 0s - loss: 0.1432\n",
      "Epoch 00004: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.1422 - val_loss: 0.2184\n",
      "Epoch 5/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.2075\n",
      "Epoch 00005: val_loss did not improve from 0.46561\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.2074 - val_loss: 0.1943\n",
      "Epoch 6/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.2302\n",
      "Epoch 00006: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.2303 - val_loss: 0.2011\n",
      "Epoch 7/30\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.2057\n",
      "Epoch 00007: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.2054 - val_loss: 0.1969\n",
      "Epoch 8/30\n",
      "494/500 [============================>.] - ETA: 0s - loss: 0.2019\n",
      "Epoch 00008: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.2035 - val_loss: 0.1962\n",
      "Epoch 9/30\n",
      "495/500 [============================>.] - ETA: 0s - loss: 0.1607\n",
      "Epoch 00009: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.1608 - val_loss: 0.1962\n",
      "Epoch 10/30\n",
      "497/500 [============================>.] - ETA: 0s - loss: 0.2455\n",
      "Epoch 00010: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.2448 - val_loss: 0.1962\n",
      "Epoch 11/30\n",
      "494/500 [============================>.] - ETA: 0s - loss: 0.1944\n",
      "Epoch 00011: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.1947 - val_loss: 0.1962\n",
      "Epoch 12/30\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.2009\n",
      "Epoch 00012: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.2006 - val_loss: 0.1962\n",
      "Epoch 13/30\n",
      "497/500 [============================>.] - ETA: 0s - loss: 0.1784\n",
      "Epoch 00013: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.1783 - val_loss: 0.1962\n",
      "Epoch 14/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.2451\n",
      "Epoch 00014: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.2450 - val_loss: 0.1962\n",
      "Epoch 15/30\n",
      "495/500 [============================>.] - ETA: 0s - loss: 0.1843\n",
      "Epoch 00015: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.1853 - val_loss: 0.1962\n",
      "Epoch 16/30\n",
      "497/500 [============================>.] - ETA: 0s - loss: 0.1812\n",
      "Epoch 00016: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.1810 - val_loss: 0.1962\n",
      "Epoch 17/30\n",
      "496/500 [============================>.] - ETA: 0s - loss: 0.2095\n",
      "Epoch 00017: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.2115 - val_loss: 0.1962\n",
      "Epoch 18/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.2231\n",
      "Epoch 00018: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.2231 - val_loss: 0.1962\n",
      "Epoch 19/30\n",
      "495/500 [============================>.] - ETA: 0s - loss: 0.1905\n",
      "Epoch 00019: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.1902 - val_loss: 0.1962\n",
      "Epoch 20/30\n",
      "497/500 [============================>.] - ETA: 0s - loss: 0.1731\n",
      "Epoch 00020: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.1732 - val_loss: 0.1962\n",
      "Epoch 21/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.2272\n",
      "Epoch 00021: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.2281 - val_loss: 0.1962\n",
      "Epoch 22/30\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.1983\n",
      "Epoch 00022: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.1982 - val_loss: 0.1962\n",
      "Epoch 23/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.2103\n",
      "Epoch 00023: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.2100 - val_loss: 0.1962\n",
      "Epoch 24/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1562\n",
      "Epoch 00024: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.1561 - val_loss: 0.1962\n",
      "Epoch 25/30\n",
      "497/500 [============================>.] - ETA: 0s - loss: 0.2565\n",
      "Epoch 00025: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.2570 - val_loss: 0.1962\n",
      "Epoch 26/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1847\n",
      "Epoch 00026: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.1847 - val_loss: 0.1962\n",
      "Epoch 27/30\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.1967\n",
      "Epoch 00027: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.1963 - val_loss: 0.1962\n",
      "Epoch 28/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1877\n",
      "Epoch 00028: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.1879 - val_loss: 0.1962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.2414\n",
      "Epoch 00029: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 0.2408 - val_loss: 0.1962\n",
      "Epoch 30/30\n",
      "497/500 [============================>.] - ETA: 0s - loss: 0.1873\n",
      "Epoch 00030: val_loss did not improve from 0.46561\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 0.1871 - val_loss: 0.1962\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "EPOCHS=30\n",
    "EVALUATION_INTERVAL=500\n",
    "time_start=time.time()\n",
    "single_step_history = single_step_model.fit(train_data_single, epochs=EPOCHS,\n",
    "                                            steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                            validation_data=val_data_single,\n",
    "                                            validation_steps=50,callbacks = [checkpoint , lr_reduce])\n",
    "time_end=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totally cost 195.12947845458984\n"
     ]
    }
   ],
   "source": [
    "print('totally cost',time_end-time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画出模型loss曲线 查看收敛效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFXHCMDOzIt8BuAU1D32nrV0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d9efc0dac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(single_step_history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对指定测试集的数据查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=0\n",
    "df=testdflist[number]\n",
    "TestX=[]\n",
    "TestY=[]\n",
    "X=df.loc[:,inputfeature].to_numpy()\n",
    "y=df.loc[:,outputfeature].to_numpy()\n",
    "lens=len(df)\n",
    "for index in range(TimeStep,lens):\n",
    "    if(int(index % TimeStep)==0):\n",
    "        TestX.append(X[index-TimeStep:index])\n",
    "        TestY.append(y[index-TimeStep:index].cumsum())\n",
    "TestX=np.array(TestX)\n",
    "TestY=np.array(TestY)\n",
    "pred = single_step_model.predict(TestX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "for i in pred:\n",
    "    result.append(i[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testY 0\n",
      "0 0.0 [0.04995978]\n",
      "1 0.3000000000029104 [0.12250221]\n",
      "2 0.19999999999708962 [0.24503885]\n",
      "3 0.3666666666686069 [0.27791715]\n",
      "4 0.5333333333328483 [0.27054843]\n",
      "5 0.5999999999985448 [0.25913814]\n",
      "6 0.6999999999970896 [0.21911395]\n",
      "7 0.9499999999970896 [0.16793858]\n",
      "8 1.0 [0.11936206]\n",
      "9 1.1999999999970896 [0.11877968]\n",
      "10 1.3999999999941792 [0.11825205]\n",
      "11 1.3999999999941792 [0.18554483]\n",
      "12 1.6999999999970896 [0.29337907]\n",
      "13 1.5999999999985448 [0.22929935]\n",
      "14 1.8000000000029104 [0.25216419]\n",
      "15 2.0 [0.31726727]\n",
      "16 2.0 [0.52098715]\n",
      "17 2.1999999999970896 [0.5556901]\n",
      "18 2.3999999999941792 [0.70333487]\n",
      "19 2.5 [0.866886]\n",
      "20 2.599999999998545 [1.0732005]\n",
      "21 2.6999999999970896 [0.89559335]\n",
      "22 2.7999999999956344 [1.1450988]\n",
      "23 2.849999999991269 [1.2879698]\n",
      "24 2.8999999999941792 [1.3704604]\n",
      "25 2.8999999999941792 [1.4246963]\n",
      "26 2.8999999999941792 [1.439525]\n",
      "27 2.8999999999941792 [1.4495518]\n",
      "28 2.8999999999941792 [1.3936507]\n",
      "29 2.8999999999941792 [1.3322879]\n",
      "testY 1\n",
      "0 0.0 [-0.03210703]\n",
      "1 0.0 [-0.07361763]\n",
      "2 0.0 [-0.1136969]\n",
      "3 0.0 [-0.14737304]\n",
      "4 0.0 [-0.17382479]\n",
      "5 0.0 [-0.19389896]\n",
      "6 0.0 [-0.20889558]\n",
      "7 0.0 [-0.22006825]\n",
      "8 0.0 [-0.22845654]\n",
      "9 0.0 [-0.23485903]\n",
      "10 0.0 [-0.23986053]\n",
      "11 0.0 [-0.24387585]\n",
      "12 0.0 [-0.2471918]\n",
      "13 0.0 [-0.25000313]\n",
      "14 0.0 [-0.2524402]\n",
      "15 0.0 [-0.25458986]\n",
      "16 0.0 [-0.2565096]\n",
      "17 0.0 [-0.25823814]\n",
      "18 0.0 [-0.25888583]\n",
      "19 0.0 [-0.26544762]\n",
      "20 0.0 [-0.26635897]\n",
      "21 0.0 [-0.27153736]\n",
      "22 0.0 [-0.2767644]\n",
      "23 0.0 [-0.28174692]\n",
      "24 0.0 [-0.2863583]\n",
      "25 0.0 [-0.2905528]\n",
      "26 0.0 [-0.29433385]\n",
      "27 0.0 [-0.29772648]\n",
      "28 0.0 [-0.3011439]\n",
      "29 0.0 [-0.30383992]\n",
      "testY 2\n",
      "0 0.0 [-0.03301468]\n",
      "1 0.0 [-0.07967109]\n",
      "2 0.0 [-0.12545116]\n",
      "3 0.0 [-0.16440852]\n",
      "4 0.0 [-0.19534253]\n",
      "5 0.0 [-0.21907224]\n",
      "6 0.0 [-0.23701984]\n",
      "7 0.0 [-0.2505953]\n",
      "8 0.0 [-0.26097715]\n",
      "9 0.0 [-0.26907113]\n",
      "10 0.0 [-0.2755394]\n",
      "11 0.0 [-0.28084937]\n",
      "12 0.0 [-0.28532386]\n",
      "13 0.0 [-0.28918147]\n",
      "14 0.0 [-0.29256898]\n",
      "15 0.0 [-0.29558414]\n",
      "16 0.0 [-0.29829293]\n",
      "17 0.0 [-0.30074024]\n",
      "18 0.0 [-0.3029579]\n",
      "19 0.0 [-0.30496967]\n",
      "20 0.0 [-0.30679405]\n",
      "21 0.0 [-0.30844688]\n",
      "22 0.0 [-0.30994186]\n",
      "23 0.0 [-0.31129146]\n",
      "24 0.0 [-0.31250733]\n",
      "25 0.0 [-0.3136005]\n",
      "26 0.0 [-0.3145815]\n",
      "27 0.0 [-0.31546012]\n",
      "28 0.0 [-0.3162457]\n",
      "29 0.0 [-0.31694686]\n",
      "testY 3\n",
      "0 0.0 [-0.03301468]\n",
      "1 0.0 [-0.07967109]\n",
      "2 0.0 [-0.12545116]\n",
      "3 0.0 [-0.16440852]\n",
      "4 0.0 [-0.19534253]\n",
      "5 0.0 [-0.21907224]\n",
      "6 0.0 [-0.23701984]\n",
      "7 0.0 [-0.2505953]\n",
      "8 0.0 [-0.26140025]\n",
      "9 0.0 [-0.26949516]\n",
      "10 0.0 [-0.275856]\n",
      "11 0.0 [-0.28099924]\n",
      "12 0.0 [-0.28527537]\n",
      "13 0.0 [-0.2889224]\n",
      "14 0.0 [-0.2920993]\n",
      "15 0.0 [-0.29491168]\n",
      "16 0.0 [-0.29742965]\n",
      "17 0.0 [-0.29970062]\n",
      "18 0.0 [-0.30175713]\n",
      "19 0.0 [-0.30362302]\n",
      "20 0.0 [-0.3053162]\n",
      "21 0.0 [-0.3068516]\n",
      "22 0.0 [-0.3082419]\n",
      "23 0.0 [-0.3094986]\n",
      "24 0.0 [-0.3106321]\n",
      "25 0.0 [-0.3116525]\n",
      "26 0.0 [-0.31256938]\n",
      "27 0.0 [-0.31339142]\n",
      "28 0.0 [-0.31412733]\n",
      "29 0.0 [-0.31478477]\n",
      "testY 4\n",
      "0 0.0 [-0.03362913]\n",
      "1 0.0 [-0.08064278]\n",
      "2 0.0 [-0.12655292]\n",
      "3 0.0 [-0.1654689]\n",
      "4 0.0 [-0.19624494]\n",
      "5 0.0 [-0.2197463]\n",
      "6 0.0 [-0.23742947]\n",
      "7 0.0 [-0.25035173]\n",
      "8 0.0 [-0.25780725]\n",
      "9 0.0 [-0.26254204]\n",
      "10 0.0 [-0.26525506]\n",
      "11 0.0 [-0.266656]\n",
      "12 0.0 [-0.2671926]\n",
      "13 0.0 [-0.26716343]\n",
      "14 0.0 [-0.26677263]\n",
      "15 0.0 [-0.26616216]\n",
      "16 0.0 [-0.26543093]\n",
      "17 0.0 [-0.2646472]\n",
      "18 0.0 [-0.2638566]\n",
      "19 0.0 [-0.26308918]\n",
      "20 0.0 [-0.26236326]\n",
      "21 0.0 [-0.261689]\n",
      "22 0.0 [-0.2610709]\n",
      "23 0.0 [-0.26051003]\n",
      "24 0.0 [-0.2600048]\n",
      "25 0.0 [-0.25992796]\n",
      "26 0.0 [-0.25910667]\n",
      "27 0.0 [-0.25866586]\n",
      "28 0.0 [-0.2586829]\n",
      "29 0.0 [-0.2579644]\n",
      "testY 5\n",
      "0 0.0 [-0.03129078]\n",
      "1 0.0 [-0.03320733]\n",
      "2 0.10000000000582077 [0.19302504]\n",
      "3 0.20000000000436557 [0.12180755]\n",
      "4 0.20000000000436557 [0.24469082]\n",
      "5 0.20000000000436557 [0.16008423]\n",
      "6 0.3000000000029104 [0.27171534]\n",
      "7 0.4000000000014552 [0.35414642]\n",
      "8 0.5 [0.66531736]\n",
      "9 0.6000000000058208 [0.6455268]\n",
      "10 0.7000000000043656 [0.80927056]\n",
      "11 0.9000000000014552 [0.86730254]\n",
      "12 1.0 [1.0065366]\n",
      "13 1.1000000000058208 [1.205079]\n",
      "14 1.3000000000029104 [1.3472872]\n",
      "15 1.4000000000014552 [1.612666]\n",
      "16 1.5 [1.6474363]\n",
      "17 1.6000000000058208 [1.7708473]\n",
      "18 1.7000000000043656 [2.0202048]\n",
      "19 1.8000000000029104 [1.9668348]\n",
      "20 1.9000000000014552 [2.1544814]\n",
      "21 2.1000000000058208 [2.3371568]\n",
      "22 2.2000000000043656 [2.4441874]\n",
      "23 2.3000000000029104 [2.4551158]\n",
      "24 2.400000000001455 [2.6280222]\n",
      "25 2.5 [2.7919838]\n",
      "26 2.6000000000058208 [2.7898896]\n",
      "27 2.7000000000043656 [2.8548312]\n",
      "28 2.8000000000029104 [2.9526837]\n",
      "29 2.900000000001455 [3.0139713]\n",
      "testY 6\n",
      "0 0.0999999999985448 [0.02617256]\n",
      "1 0.20000000000436557 [0.17057155]\n",
      "2 0.3000000000029104 [0.33566153]\n",
      "3 0.3000000000029104 [0.25010535]\n",
      "4 0.4000000000014552 [0.31580764]\n",
      "5 0.4000000000014552 [0.32038182]\n",
      "6 0.4000000000014552 [0.31428584]\n",
      "7 0.4000000000014552 [0.25005683]\n",
      "8 0.5 [0.28339183]\n",
      "9 0.5999999999985448 [0.42183867]\n",
      "10 0.7000000000043656 [0.37793615]\n",
      "11 0.8000000000029104 [0.5750005]\n",
      "12 0.8000000000029104 [0.61811036]\n",
      "13 0.9000000000014552 [0.7011258]\n",
      "14 0.9000000000014552 [0.85342556]\n",
      "15 1.0999999999985448 [1.0847247]\n",
      "16 1.2000000000043656 [1.1782038]\n",
      "17 1.2000000000043656 [1.3210912]\n",
      "18 1.3000000000029104 [1.4856403]\n",
      "19 1.4000000000014552 [1.6161631]\n",
      "20 1.5999999999985448 [1.808221]\n",
      "21 1.7000000000043656 [1.8639574]\n",
      "22 1.7000000000043656 [1.7740012]\n",
      "23 1.8000000000029104 [2.0012324]\n",
      "24 2.0 [2.2194006]\n",
      "25 2.099999999998545 [2.3727176]\n",
      "26 2.099999999998545 [2.4324574]\n",
      "27 2.2000000000043656 [2.5121331]\n",
      "28 2.3000000000029104 [2.4837828]\n",
      "29 2.3000000000029104 [2.453754]\n",
      "testY 7\n",
      "0 0.0 [0.00763611]\n",
      "1 0.0 [0.0276889]\n",
      "2 0.0999999999985448 [0.03758791]\n",
      "3 0.1999999999970896 [0.23303585]\n",
      "4 0.29999999999563437 [0.28088152]\n",
      "5 0.40000000000145514 [0.58374214]\n",
      "6 0.5999999999985447 [0.5674492]\n",
      "7 0.6999999999970895 [0.7080749]\n",
      "8 0.7999999999956343 [0.6795233]\n",
      "9 0.9000000000014551 [0.9561294]\n",
      "10 0.9000000000014551 [0.9605239]\n",
      "11 0.9000000000014551 [1.0174047]\n",
      "12 0.9000000000014551 [1.0618101]\n",
      "13 0.9000000000014551 [1.0888746]\n",
      "14 0.9000000000014551 [1.1000446]\n",
      "15 0.9000000000014551 [1.0984826]\n",
      "16 0.9000000000014551 [1.0854838]\n",
      "17 0.9000000000014551 [1.0631716]\n",
      "18 0.9000000000014551 [1.0314653]\n",
      "19 0.9000000000014551 [1.0574756]\n",
      "20 0.9999999999999999 [1.1159012]\n",
      "21 1.1999999999970894 [1.1165667]\n",
      "22 1.2999999999956342 [1.0772008]\n",
      "23 1.400000000001455 [1.2141075]\n",
      "24 1.4999999999999998 [1.3723664]\n",
      "25 1.5999999999985446 [1.7488495]\n",
      "26 1.6999999999970894 [1.8753722]\n",
      "27 1.7999999999956342 [2.0334253]\n",
      "28 1.7999999999956342 [2.1699743]\n",
      "29 1.900000000001455 [2.1965628]\n",
      "testY 8\n",
      "0 0.0 [0.03425378]\n",
      "1 0.0999999999985448 [0.3688463]\n",
      "2 0.1999999999970896 [0.3095506]\n",
      "3 0.1999999999970896 [0.30542052]\n",
      "4 0.1999999999970896 [0.2729868]\n",
      "5 0.1999999999970896 [0.2559281]\n",
      "6 0.1999999999970896 [0.22799021]\n",
      "7 0.1999999999970896 [0.18453263]\n",
      "8 0.1999999999970896 [0.14060172]\n",
      "9 0.1999999999970896 [0.09590579]\n",
      "10 0.1999999999970896 [0.0487579]\n",
      "11 0.1999999999970896 [0.00480437]\n",
      "12 0.1999999999970896 [0.01911982]\n",
      "13 0.1999999999970896 [0.1332438]\n",
      "14 0.29999999999563437 [0.41186592]\n",
      "15 0.3999999999941792 [0.3249926]\n",
      "16 0.3999999999941792 [0.36186916]\n",
      "17 0.49999999999999994 [0.4980313]\n",
      "18 0.5999999999985447 [0.5846603]\n",
      "19 0.6999999999970895 [0.5977696]\n",
      "20 0.7999999999956343 [0.64304876]\n",
      "21 0.7999999999956343 [0.7487431]\n",
      "22 0.8999999999941791 [0.86340195]\n",
      "23 0.9999999999999999 [0.99033767]\n",
      "24 1.0999999999985446 [1.2613983]\n",
      "25 1.1999999999970894 [1.2927096]\n",
      "26 1.2999999999956342 [1.3142432]\n",
      "27 1.2999999999956342 [1.4563513]\n",
      "28 1.399999999994179 [1.5180569]\n",
      "29 1.4999999999999998 [1.7816056]\n",
      "testY 9\n",
      "0 0.0999999999985448 [0.01867464]\n",
      "1 0.1999999999970896 [0.13696074]\n",
      "2 0.1999999999970896 [0.28564402]\n",
      "3 0.29999999999563437 [0.34200186]\n",
      "4 0.3999999999941792 [0.43700358]\n",
      "5 0.3999999999941792 [0.47628957]\n",
      "6 0.3999999999941792 [0.4956796]\n",
      "7 0.49999999999999994 [0.5591355]\n",
      "8 0.49999999999999994 [0.6980767]\n",
      "9 0.6999999999970895 [0.9007575]\n",
      "10 0.7999999999956343 [0.9995286]\n",
      "11 0.8999999999941791 [1.2638814]\n",
      "12 0.9999999999999999 [1.2979381]\n",
      "13 0.9999999999999999 [1.3168511]\n",
      "14 0.9999999999999999 [1.3735087]\n",
      "15 1.0999999999985446 [1.5021791]\n",
      "16 1.1999999999970894 [1.643143]\n",
      "17 1.2999999999956342 [1.9169507]\n",
      "18 1.399999999994179 [2.0946884]\n",
      "19 1.4999999999999998 [2.1273296]\n",
      "20 1.5999999999985446 [2.174554]\n",
      "21 1.6999999999970894 [2.249134]\n",
      "22 1.6999999999970894 [2.2381346]\n",
      "23 1.7999999999956342 [2.1897833]\n",
      "24 1.899999999994179 [2.3919764]\n",
      "25 1.9999999999999998 [2.5563476]\n",
      "26 2.0999999999985444 [2.6929283]\n",
      "27 2.299999999995634 [2.8265939]\n",
      "28 2.299999999995634 [2.8531244]\n",
      "29 2.299999999995634 [2.8371105]\n",
      "testY 10\n",
      "0 0.0 [0.02182144]\n",
      "1 0.2000000000043656 [0.21735261]\n",
      "2 0.3000000000029104 [0.34358728]\n",
      "3 0.4000000000014552 [0.27649477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.5 [0.3991081]\n",
      "5 0.7000000000043656 [0.50652176]\n",
      "6 0.8000000000029104 [0.6344116]\n",
      "7 0.9000000000014552 [0.96810883]\n",
      "8 1.0 [1.0897877]\n",
      "9 1.0 [1.2203507]\n",
      "10 1.0 [1.1217196]\n",
      "11 1.0999999999985448 [1.3674487]\n",
      "12 1.2000000000043656 [1.5971992]\n",
      "13 1.4000000000014552 [1.8347135]\n",
      "14 1.5 [1.8106778]\n",
      "15 1.5999999999985448 [1.9474845]\n",
      "16 1.7000000000043656 [2.2735217]\n",
      "17 1.9000000000014552 [2.5011857]\n",
      "18 2.0 [2.5816112]\n",
      "19 2.099999999998545 [2.68184]\n",
      "20 2.3000000000029104 [2.8352022]\n",
      "21 2.400000000001455 [2.9698088]\n",
      "22 2.400000000001455 [2.9943886]\n",
      "23 2.400000000001455 [3.0008166]\n",
      "24 2.400000000001455 [2.9576797]\n",
      "25 2.599999999998545 [3.0506763]\n",
      "26 2.7000000000043656 [3.0884542]\n",
      "27 2.8000000000029104 [3.179393]\n",
      "28 2.900000000001455 [3.2061572]\n",
      "29 2.900000000001455 [3.1929212]\n",
      "testY 11\n",
      "0 0.0 [0.02273758]\n",
      "1 0.0 [0.01543907]\n",
      "2 0.0 [-0.01899709]\n",
      "3 0.0999999999985448 [0.16953681]\n",
      "4 0.1999999999970896 [0.27279916]\n",
      "5 0.3000000000029104 [0.40716904]\n",
      "6 0.5 [0.5456036]\n",
      "7 0.5999999999985448 [0.7965111]\n",
      "8 0.6999999999970896 [0.83505696]\n",
      "9 0.8000000000029104 [1.052732]\n",
      "10 0.9000000000014552 [1.1763523]\n",
      "11 1.0 [1.2777295]\n",
      "12 1.0999999999985448 [1.5357189]\n",
      "13 1.1999999999970896 [1.802534]\n",
      "14 1.4000000000014552 [2.0448759]\n",
      "15 1.5 [2.2664661]\n",
      "16 1.5999999999985448 [2.4602952]\n",
      "17 1.6999999999970896 [2.6531718]\n",
      "18 1.9000000000014552 [2.7554512]\n",
      "19 2.0 [2.733512]\n",
      "20 2.099999999998545 [2.9053597]\n",
      "21 2.1999999999970896 [2.9662561]\n",
      "22 2.1999999999970896 [2.9466019]\n",
      "23 2.1999999999970896 [2.9094512]\n",
      "24 2.1999999999970896 [2.8720407]\n",
      "25 2.1999999999970896 [2.8144302]\n",
      "26 2.1999999999970896 [2.7425961]\n",
      "27 2.1999999999970896 [2.672059]\n",
      "28 2.1999999999970896 [2.6023297]\n",
      "29 2.1999999999970896 [2.5230143]\n",
      "testY 12\n",
      "0 0.0 [-0.00360492]\n",
      "1 0.0 [-0.02459194]\n",
      "2 0.0 [-0.06462009]\n",
      "3 0.0 [-0.09449057]\n",
      "4 0.0 [-0.13517788]\n",
      "5 0.0 [-0.16547714]\n",
      "6 0.0 [-0.18387543]\n",
      "7 0.0 [-0.21345292]\n",
      "8 0.0 [-0.2263984]\n",
      "9 0.0 [-0.2506016]\n",
      "10 0.0 [-0.2592981]\n",
      "11 0.0 [-0.27366638]\n",
      "12 0.0 [-0.28716007]\n",
      "13 0.0 [-0.29952374]\n",
      "14 0.0 [-0.31071988]\n",
      "15 0.0 [-0.32009545]\n",
      "16 0.0 [-0.32888308]\n",
      "17 0.0 [-0.33679026]\n",
      "18 0.0 [-0.34386355]\n",
      "19 0.0 [-0.35016695]\n",
      "20 0.0 [-0.35576633]\n",
      "21 0.0 [-0.36072665]\n",
      "22 0.0 [-0.36510977]\n",
      "23 0.0 [-0.36897397]\n",
      "24 0.0 [-0.37237337]\n",
      "25 0.0 [-0.3753578]\n",
      "26 0.0 [-0.3779731]\n",
      "27 0.0 [-0.38026088]\n",
      "28 0.0 [-0.382259]\n",
      "29 0.0 [-0.38400134]\n",
      "testY 13\n",
      "0 0.0 [-0.00243876]\n",
      "1 0.0 [-0.02889596]\n",
      "2 0.0 [-0.06420952]\n",
      "3 0.0 [-0.1000879]\n",
      "4 0.0 [-0.1342258]\n",
      "5 0.0 [-0.16508661]\n",
      "6 0.0 [-0.19237538]\n",
      "7 0.0 [-0.21628076]\n",
      "8 0.0 [-0.23717551]\n",
      "9 0.0 [-0.2554703]\n",
      "10 0.0 [-0.27154666]\n",
      "11 0.0 [-0.28573245]\n",
      "12 0.0 [-0.29829878]\n",
      "13 0.0 [-0.30946562]\n",
      "14 0.0 [-0.31941092]\n",
      "15 0.0 [-0.32827953]\n",
      "16 0.0 [-0.33619136]\n",
      "17 0.0 [-0.34324765]\n",
      "18 0.0 [-0.34953523]\n",
      "19 0.0 [-0.35513103]\n",
      "20 0.0 [-0.36010307]\n",
      "21 0.0 [-0.36451334]\n",
      "22 0.0 [-0.36841786]\n",
      "23 0.0 [-0.37186825]\n",
      "24 0.0 [-0.37491143]\n",
      "25 0.0 [-0.37759063]\n",
      "26 0.0 [-0.379945]\n",
      "27 0.0 [-0.38201064]\n",
      "28 0.0 [-0.38369232]\n",
      "29 0.0 [-0.38500035]\n",
      "testY 14\n",
      "0 0.0 [-0.00072433]\n",
      "1 0.0 [-0.02593806]\n",
      "2 0.0 [-0.06047302]\n",
      "3 0.0 [-0.09669483]\n",
      "4 0.0 [-0.13107623]\n",
      "5 0.0 [-0.1622308]\n",
      "6 0.0 [-0.15249605]\n",
      "7 0.10000000000582077 [-0.06146402]\n",
      "8 0.20000000000436557 [-0.07270912]\n",
      "9 0.20000000000436557 [-0.0719809]\n",
      "10 0.20000000000436557 [-0.07842385]\n",
      "11 0.20000000000436557 [-0.09322331]\n",
      "12 0.20000000000436557 [-0.11372084]\n",
      "13 0.3000000000029104 [-0.0767012]\n",
      "14 0.4000000000014552 [-0.04033779]\n",
      "15 0.5 [0.03260472]\n",
      "16 0.6000000000058208 [0.05474502]\n",
      "17 0.7000000000043656 [0.18580951]\n",
      "18 0.8000000000029104 [0.15196873]\n",
      "19 1.0 [0.27241907]\n",
      "20 1.1000000000058208 [0.42356026]\n",
      "21 1.2000000000043656 [0.57966065]\n",
      "22 1.4000000000014552 [0.7346035]\n",
      "23 1.5 [0.60396856]\n",
      "24 1.6000000000058208 [0.81162816]\n",
      "25 1.7000000000043656 [1.0530388]\n",
      "26 1.8000000000029104 [0.90789735]\n",
      "27 1.9000000000014552 [1.1180575]\n",
      "28 2.1000000000058208 [1.2645129]\n",
      "29 2.2000000000043656 [1.628891]\n",
      "testY 15\n",
      "0 0.0999999999985448 [0.0484662]\n",
      "1 0.1999999999970896 [0.22318645]\n",
      "2 0.29999999999563437 [0.49030453]\n",
      "3 0.40000000000145514 [0.48261184]\n",
      "4 0.49999999999999994 [0.6582884]\n",
      "5 0.5999999999985447 [0.80932933]\n",
      "6 0.7999999999956343 [1.0796609]\n",
      "7 0.7999999999956343 [0.98737526]\n",
      "8 0.9999999999999999 [1.1625934]\n",
      "9 1.0999999999985446 [1.1709259]\n",
      "10 1.0999999999985446 [1.1931822]\n",
      "11 1.1999999999970894 [1.3149794]\n",
      "12 1.400000000001455 [1.3990908]\n",
      "13 1.4999999999999998 [1.4441942]\n",
      "14 1.4999999999999998 [1.46037]\n",
      "15 1.4999999999999998 [1.3822058]\n",
      "16 1.5999999999985446 [1.3516574]\n",
      "17 1.6999999999970894 [1.5806246]\n",
      "18 1.900000000001455 [1.9355917]\n",
      "19 1.900000000001455 [2.0082235]\n",
      "20 1.900000000001455 [2.0946076]\n",
      "21 1.900000000001455 [2.1467538]\n",
      "22 1.9999999999999998 [2.1666632]\n",
      "23 1.9999999999999998 [2.0936222]\n",
      "24 2.0999999999985444 [2.257802]\n",
      "25 2.299999999995634 [2.4465013]\n",
      "26 2.4000000000014547 [2.5523982]\n",
      "27 2.4999999999999996 [2.5245645]\n",
      "28 2.5999999999985444 [2.5913525]\n",
      "29 2.699999999997089 [2.6412344]\n",
      "testY 16\n",
      "0 0.0999999999985448 [0.17178659]\n",
      "1 0.20000000000436557 [0.10743003]\n",
      "2 0.3000000000029104 [0.4601639]\n",
      "3 0.3000000000029104 [0.42686492]\n",
      "4 0.3000000000029104 [0.44381213]\n",
      "5 0.3000000000029104 [0.5093396]\n",
      "6 0.4000000000014552 [0.41422287]\n",
      "7 0.5999999999985448 [0.6379713]\n",
      "8 0.7000000000043656 [0.508199]\n",
      "9 0.7000000000043656 [0.6916523]\n",
      "10 0.7000000000043656 [0.5966545]\n",
      "11 0.8000000000029104 [0.85391986]\n",
      "12 0.9000000000014552 [0.88364065]\n",
      "13 0.9000000000014552 [0.9688167]\n",
      "14 0.9000000000014552 [1.0523021]\n",
      "15 0.9000000000014552 [1.1197684]\n",
      "16 0.9000000000014552 [1.081236]\n",
      "17 1.0 [1.2656474]\n",
      "18 1.0999999999985448 [1.3243153]\n",
      "19 1.0999999999985448 [1.2569413]\n",
      "20 1.2000000000043656 [1.4952137]\n",
      "21 1.3000000000029104 [1.4708184]\n",
      "22 1.3000000000029104 [1.507102]\n",
      "23 1.3000000000029104 [1.5378044]\n",
      "24 1.3000000000029104 [1.5494368]\n",
      "25 1.3000000000029104 [1.5524778]\n",
      "26 1.3000000000029104 [1.552565]\n",
      "27 1.3000000000029104 [1.5536547]\n",
      "28 1.4000000000014552 [1.6863613]\n",
      "29 1.5999999999985448 [1.8499627]\n",
      "testY 17\n",
      "0 0.0 [0.04447667]\n",
      "1 0.0 [0.05257712]\n",
      "2 0.10000000000582077 [0.09936536]\n",
      "3 0.10000000000582077 [0.11617815]\n",
      "4 0.20000000000436557 [0.05263702]\n",
      "5 0.20000000000436557 [0.00565089]\n",
      "6 0.20000000000436557 [-0.03813989]\n",
      "7 0.20000000000436557 [-0.07709945]\n",
      "8 0.20000000000436557 [-0.11818276]\n",
      "9 0.20000000000436557 [-0.15171395]\n",
      "10 0.20000000000436557 [-0.17341082]\n",
      "11 0.20000000000436557 [-0.166544]\n",
      "12 0.3000000000029104 [-0.04722361]\n",
      "13 0.4000000000014552 [0.07136622]\n",
      "14 0.5 [0.10184366]\n",
      "15 0.5 [0.16496275]\n",
      "16 0.6000000000058208 [0.23414636]\n",
      "17 0.6000000000058208 [0.33633104]\n",
      "18 0.7000000000043656 [0.38688177]\n",
      "19 0.7000000000043656 [0.4186354]\n",
      "20 0.7000000000043656 [0.53941864]\n",
      "21 0.7000000000043656 [0.5947663]\n",
      "22 0.7000000000043656 [0.70110035]\n",
      "23 0.8000000000029104 [0.8078109]\n",
      "24 0.8000000000029104 [0.8830495]\n",
      "25 0.8000000000029104 [0.94060785]\n",
      "26 0.8000000000029104 [0.9721702]\n",
      "27 0.8000000000029104 [0.98171467]\n",
      "28 0.8000000000029104 [0.9681329]\n",
      "29 0.8000000000029104 [0.9449934]\n",
      "testY 18\n",
      "0 0.0 [0.02926104]\n",
      "1 0.0 [0.02634422]\n",
      "2 0.0 [0.00583678]\n",
      "3 0.0 [-0.02359195]\n",
      "4 0.0 [-0.00763323]\n",
      "5 0.0999999999985448 [-0.00504406]\n",
      "6 0.0999999999985448 [0.08443223]\n",
      "7 0.1999999999970896 [0.08425572]\n",
      "8 0.1999999999970896 [0.13947786]\n",
      "9 0.3000000000029104 [0.22178738]\n",
      "10 0.4000000000014552 [0.2393509]\n",
      "11 0.5 [0.3721898]\n",
      "12 0.5999999999985448 [0.23831789]\n",
      "13 0.5999999999985448 [0.40282792]\n",
      "14 0.5999999999985448 [0.36894795]\n",
      "15 0.5999999999985448 [0.36101562]\n",
      "16 0.5999999999985448 [0.35725236]\n",
      "17 0.6999999999970896 [0.560792]\n",
      "18 0.8000000000029104 [0.6367462]\n",
      "19 0.8000000000029104 [0.8092533]\n",
      "20 0.8000000000029104 [0.72480863]\n",
      "21 0.9000000000014552 [0.9596155]\n",
      "22 1.0 [1.1575971]\n",
      "23 1.0999999999985448 [1.2115376]\n",
      "24 1.0999999999985448 [1.4079545]\n",
      "25 1.1999999999970896 [1.5344652]\n",
      "26 1.1999999999970896 [1.411176]\n",
      "27 1.3000000000029104 [1.733606]\n",
      "28 1.4000000000014552 [1.8303058]\n",
      "29 1.4000000000014552 [1.8095915]\n",
      "testY 19\n",
      "0 0.0999999999985448 [0.0864474]\n",
      "1 0.1999999999970896 [0.2107902]\n",
      "2 0.1999999999970896 [0.140078]\n",
      "3 0.1999999999970896 [0.08612325]\n",
      "4 0.1999999999970896 [0.03765137]\n",
      "5 0.1999999999970896 [-0.00428837]\n",
      "6 0.1999999999970896 [-0.04943208]\n",
      "7 0.1999999999970896 [-0.0927362]\n",
      "8 0.1999999999970896 [-0.10642292]\n",
      "9 0.29999999999563437 [-0.04110592]\n",
      "10 0.29999999999563437 [0.01759119]\n",
      "11 0.40000000000145514 [0.09164391]\n",
      "12 0.40000000000145514 [0.10039654]\n",
      "13 0.40000000000145514 [0.10219711]\n",
      "14 0.40000000000145514 [0.09185372]\n",
      "15 0.40000000000145514 [0.07219358]\n",
      "16 0.40000000000145514 [0.0465416]\n",
      "17 0.40000000000145514 [0.01564345]\n",
      "18 0.40000000000145514 [-0.02227929]\n",
      "19 0.40000000000145514 [0.03586373]\n",
      "20 0.49999999999999994 [0.07240569]\n",
      "21 0.5999999999985447 [0.21869217]\n",
      "22 0.6999999999970895 [0.26380837]\n",
      "23 0.7999999999956343 [0.28406805]\n",
      "24 0.7999999999956343 [0.32729056]\n",
      "25 0.9000000000014551 [0.57930446]\n",
      "26 0.9999999999999999 [0.70826083]\n",
      "27 1.0999999999985446 [0.6605228]\n",
      "28 1.2999999999956342 [0.90242106]\n",
      "29 1.400000000001455 [0.95848566]\n",
      "testY 20\n",
      "0 0.0 [0.07062059]\n",
      "1 0.0999999999985448 [0.3039655]\n",
      "2 0.1999999999970896 [0.2645042]\n",
      "3 0.1999999999970896 [0.15525773]\n",
      "4 0.29999999999563437 [0.26499015]\n",
      "5 0.3999999999941792 [0.457811]\n",
      "6 0.49999999999999994 [0.53833467]\n",
      "7 0.5999999999985447 [0.64733183]\n",
      "8 0.6999999999970895 [0.7520794]\n",
      "9 0.7999999999956343 [0.8340097]\n",
      "10 0.7999999999956343 [0.8016456]\n",
      "11 0.7999999999956343 [0.8272441]\n",
      "12 0.8999999999941791 [0.7193771]\n",
      "13 0.9999999999999999 [1.0882505]\n",
      "14 1.0999999999985446 [1.1028285]\n",
      "15 1.1999999999970894 [1.3846354]\n",
      "16 1.399999999994179 [1.381813]\n",
      "17 1.4999999999999998 [1.4536626]\n",
      "18 1.5999999999985446 [1.6563475]\n",
      "19 1.7999999999956342 [1.8264736]\n",
      "20 1.899999999994179 [1.8430817]\n",
      "21 1.9999999999999998 [1.9226296]\n",
      "22 2.199999999997089 [2.1424613]\n",
      "23 2.299999999995634 [2.2917109]\n",
      "24 2.299999999995634 [2.3037822]\n",
      "25 2.299999999995634 [2.3141942]\n",
      "26 2.299999999995634 [2.231329]\n",
      "27 2.399999999994179 [2.325021]\n",
      "28 2.5999999999985444 [2.432704]\n",
      "29 2.699999999997089 [2.5854187]\n",
      "testY 21\n",
      "0 0.0999999999985448 [-0.0044034]\n",
      "1 0.1999999999970896 [0.17703068]\n",
      "2 0.3000000000029104 [0.2505671]\n",
      "3 0.4000000000014552 [0.32011533]\n",
      "4 0.5 [0.40597978]\n",
      "5 0.5999999999985448 [0.3079321]\n",
      "6 0.5999999999985448 [0.26706728]\n",
      "7 0.6999999999970896 [0.46421266]\n",
      "8 0.9000000000014552 [0.6373612]\n",
      "9 1.0 [0.73399526]\n",
      "10 1.0 [0.8146767]\n",
      "11 1.0 [0.8789825]\n",
      "12 1.0999999999985448 [0.89325494]\n",
      "13 1.1999999999970896 [1.0849745]\n",
      "14 1.3000000000029104 [1.3117194]\n",
      "15 1.4000000000014552 [1.4791586]\n",
      "16 1.5999999999985448 [1.7210945]\n",
      "17 1.6999999999970896 [1.6284258]\n",
      "18 1.8000000000029104 [1.8470443]\n",
      "19 1.9000000000014552 [1.9270651]\n",
      "20 2.099999999998545 [2.0420246]\n",
      "21 2.1999999999970896 [2.3233151]\n",
      "22 2.3000000000029104 [2.1242392]\n",
      "23 2.400000000001455 [2.169131]\n",
      "24 2.5 [2.3116465]\n",
      "25 2.599999999998545 [2.3615808]\n",
      "26 2.8000000000029104 [2.5952978]\n",
      "27 2.8000000000029104 [2.691669]\n",
      "28 2.900000000001455 [2.5770695]\n",
      "29 3.0 [2.6591668]\n",
      "testY 22\n",
      "0 0.0999999999985448 [0.10460336]\n",
      "1 0.3000000000029104 [0.20223878]\n",
      "2 0.4000000000014552 [0.25011772]\n",
      "3 0.5 [0.37244606]\n",
      "4 0.6999999999970896 [0.42510346]\n",
      "5 0.8000000000029104 [0.5559544]\n",
      "6 0.9000000000014552 [0.7034671]\n",
      "7 1.0 [0.84453946]\n",
      "8 1.1999999999970896 [1.0459348]\n",
      "9 1.3000000000029104 [1.1041696]\n",
      "10 1.4000000000014552 [1.296571]\n",
      "11 1.5 [1.4356238]\n",
      "12 1.5 [1.4870124]\n",
      "13 1.5 [1.5015717]\n",
      "14 1.5 [1.5075859]\n",
      "15 1.5 [1.4928972]\n",
      "16 1.5 [1.4655528]\n",
      "17 1.5 [1.4330003]\n",
      "18 1.5 [1.3867102]\n",
      "19 1.5 [1.3399653]\n",
      "20 1.5 [1.291232]\n",
      "21 1.5 [1.2415633]\n",
      "22 1.5 [1.1913142]\n",
      "23 1.5 [1.1409183]\n",
      "24 1.5 [1.0904973]\n",
      "25 1.5 [1.0398555]\n",
      "26 1.5 [0.9892505]\n",
      "27 1.5 [0.93820196]\n",
      "28 1.5 [0.88694584]\n",
      "29 1.5 [0.83543295]\n",
      "testY 23\n",
      "0 0.0 [0.02219339]\n",
      "1 0.0 [0.01286619]\n",
      "2 0.0 [-0.01267436]\n",
      "3 0.0 [-0.0467962]\n",
      "4 0.0 [-0.08356814]\n",
      "5 0.0 [-0.12051047]\n",
      "6 0.0 [-0.15617362]\n",
      "7 0.0 [-0.1906481]\n",
      "8 0.0 [-0.22224164]\n",
      "9 0.0 [-0.2510712]\n",
      "10 0.0 [-0.27716878]\n",
      "11 0.0 [-0.3006442]\n",
      "12 0.0 [-0.3225444]\n",
      "13 0.0 [-0.34539512]\n",
      "14 0.0 [-0.36491248]\n",
      "15 0.0 [-0.38120633]\n",
      "16 0.0 [-0.39500722]\n",
      "17 0.0 [-0.40672544]\n",
      "18 0.0 [-0.41669193]\n",
      "19 0.0 [-0.42604452]\n",
      "20 0.0 [-0.43368462]\n",
      "21 0.0 [-0.4401055]\n",
      "22 0.0 [-0.445522]\n",
      "23 0.0 [-0.4500993]\n",
      "24 0.0 [-0.45010227]\n",
      "25 0.0 [-0.4464904]\n",
      "26 0.0 [-0.44287336]\n",
      "27 0.0 [-0.4457605]\n",
      "28 0.0 [-0.44396776]\n",
      "29 0.0 [-0.4398919]\n",
      "testY 24\n",
      "0 0.0 [0.01375003]\n",
      "1 0.0 [-0.00080273]\n",
      "2 0.0 [-0.0299076]\n",
      "3 0.0 [-0.06437133]\n",
      "4 0.0 [-0.09979173]\n",
      "5 0.0 [-0.13379127]\n",
      "6 0.0 [-0.16522954]\n",
      "7 0.0 [-0.19367553]\n",
      "8 0.0 [-0.21908875]\n",
      "9 0.0 [-0.24162982]\n",
      "10 0.0 [-0.26234668]\n",
      "11 0.0 [-0.2802918]\n",
      "12 0.0 [-0.2960161]\n",
      "13 0.0 [-0.30981836]\n",
      "14 0.0 [-0.32194382]\n",
      "15 0.0 [-0.3326031]\n",
      "16 0.0 [-0.34197646]\n",
      "17 0.0 [-0.3502186]\n",
      "18 0.0 [-0.35746303]\n",
      "19 0.0 [-0.36382586]\n",
      "20 0.0 [-0.36940867]\n",
      "21 0.0 [-0.3743012]\n",
      "22 0.0 [-0.37940583]\n",
      "23 0.0 [-0.3835131]\n",
      "24 0.0 [-0.38699073]\n",
      "25 0.0 [-0.38995767]\n",
      "26 0.0 [-0.3924932]\n",
      "27 0.0 [-0.39466238]\n",
      "28 0.0 [-0.39651936]\n",
      "29 0.0 [-0.39810956]\n",
      "testY 25\n",
      "0 0.0 [0.01149582]\n",
      "1 0.0 [-0.0048375]\n",
      "2 0.0 [-0.03448941]\n",
      "3 0.0 [-0.0693565]\n",
      "4 0.0 [-0.10496347]\n",
      "5 0.0 [-0.13975188]\n",
      "6 0.0 [-0.17148142]\n",
      "7 0.0 [-0.19999127]\n",
      "8 0.0 [-0.22531612]\n",
      "9 0.0 [-0.24766897]\n",
      "10 0.0 [-0.26734072]\n",
      "11 0.0 [-0.2846378]\n",
      "12 0.0 [-0.29985115]\n",
      "13 0.0 [-0.31324202]\n",
      "14 0.0 [-0.32503802]\n",
      "15 0.0 [-0.33543533]\n",
      "16 0.0 [-0.34460193]\n",
      "17 0.0 [-0.35268223]\n",
      "18 0.0 [-0.35980093]\n",
      "19 0.0 [-0.3660672]\n",
      "20 0.0 [-0.37157667]\n",
      "21 0.0 [-0.37641445]\n",
      "22 0.0 [-0.38065583]\n",
      "23 0.0 [-0.38436866]\n",
      "24 0.0 [-0.38761336]\n",
      "25 0.0 [-0.39044443]\n",
      "26 0.0 [-0.39291054]\n",
      "27 0.0 [-0.3950553]\n",
      "28 0.0 [-0.40044308]\n",
      "29 0.0 [-0.3916367]\n",
      "testY 26\n",
      "0 0.0999999999985448 [0.03172942]\n",
      "1 0.0999999999985448 [0.04476262]\n",
      "2 0.0999999999985448 [0.03610025]\n",
      "3 0.0999999999985448 [0.02675304]\n",
      "4 0.1999999999970896 [0.01661601]\n",
      "5 0.1999999999970896 [-0.02121404]\n",
      "6 0.3000000000029104 [0.0813895]\n",
      "7 0.4000000000014552 [0.21027517]\n",
      "8 0.5 [0.25739637]\n",
      "9 0.5999999999985448 [0.32842806]\n",
      "10 0.6999999999970896 [0.4557312]\n",
      "11 0.8000000000029104 [0.49722305]\n",
      "12 1.0 [0.5857179]\n",
      "13 1.0999999999985448 [0.7508317]\n",
      "14 1.1999999999970896 [0.913091]\n",
      "15 1.4000000000014552 [1.2050055]\n",
      "16 1.5 [1.2340555]\n",
      "17 1.5999999999985448 [1.3158367]\n",
      "18 1.6999999999970896 [1.6174456]\n",
      "19 1.8000000000029104 [1.5732154]\n",
      "20 1.9000000000014552 [1.6865687]\n",
      "21 2.099999999998545 [1.9533265]\n",
      "22 2.1999999999970896 [2.0656846]\n",
      "23 2.3000000000029104 [2.0952377]\n",
      "24 2.400000000001455 [2.2441437]\n",
      "25 2.5 [2.3117654]\n",
      "26 2.599999999998545 [2.4312115]\n",
      "27 2.6999999999970896 [2.547594]\n",
      "28 2.900000000001455 [2.6418362]\n",
      "29 2.900000000001455 [2.6703339]\n",
      "testY 27\n",
      "0 0.0999999999985448 [0.06559083]\n",
      "1 0.1999999999970896 [0.08319696]\n",
      "2 0.4000000000014552 [0.39064348]\n",
      "3 0.4000000000014552 [0.23778072]\n",
      "4 0.5999999999985448 [0.23427361]\n",
      "5 0.6999999999970896 [0.31392395]\n",
      "6 0.7999999999956344 [0.74093145]\n",
      "7 0.9000000000014552 [0.7300315]\n",
      "8 1.0 [0.85049134]\n",
      "9 1.0999999999985448 [0.824358]\n",
      "10 1.1999999999970896 [0.7210043]\n",
      "11 1.2999999999956344 [0.85237926]\n",
      "12 1.5 [1.0133848]\n",
      "13 1.5999999999985448 [1.4218361]\n",
      "14 1.5999999999985448 [1.5623322]\n",
      "15 1.6999999999970896 [1.7040858]\n",
      "16 1.6999999999970896 [1.8301642]\n",
      "17 1.6999999999970896 [1.6462955]\n",
      "18 1.7999999999956344 [1.8663144]\n",
      "19 1.9000000000014552 [2.0796888]\n",
      "20 2.099999999998545 [2.2495427]\n",
      "21 2.1999999999970896 [2.3645058]\n",
      "22 2.2999999999956344 [2.3900776]\n",
      "23 2.2999999999956344 [2.3949535]\n",
      "24 2.2999999999956344 [2.3851671]\n",
      "25 2.2999999999956344 [2.344192]\n",
      "26 2.2999999999956344 [2.3147988]\n",
      "27 2.5 [2.4036977]\n",
      "28 2.599999999998545 [2.4355574]\n",
      "29 2.6999999999970896 [2.6056378]\n",
      "testY 28\n",
      "0 0.0999999999985448 [0.02906702]\n",
      "1 0.0999999999985448 [0.01368773]\n",
      "2 0.0999999999985448 [-0.01326289]\n",
      "3 0.20000000000436557 [-0.01987923]\n",
      "4 0.3000000000029104 [0.17487644]\n",
      "5 0.4000000000014552 [0.4675687]\n",
      "6 0.5 [0.42344877]\n",
      "7 0.5 [0.42428365]\n",
      "8 0.5 [0.4256842]\n",
      "9 0.5 [0.4179626]\n",
      "10 0.5 [0.400954]\n",
      "11 0.5 [0.37851265]\n",
      "12 0.5 [0.35082364]\n",
      "13 0.5 [0.3181156]\n",
      "14 0.5 [0.28154898]\n",
      "15 0.5 [0.30761948]\n",
      "16 0.5999999999985448 [0.39868313]\n",
      "17 0.7000000000043656 [0.6080832]\n",
      "18 0.8000000000029104 [0.7513613]\n",
      "19 0.9000000000014552 [0.64828837]\n",
      "20 1.0 [0.67966217]\n",
      "21 1.0 [0.8451141]\n",
      "22 1.0 [0.99102217]\n",
      "23 1.0 [1.113299]\n",
      "24 1.0 [1.2080687]\n",
      "25 1.0 [1.2702874]\n",
      "26 1.0 [1.3030528]\n",
      "27 1.0 [1.3123542]\n",
      "28 1.0999999999985448 [1.1695404]\n",
      "29 1.2000000000043656 [1.1800437]\n",
      "testY 29\n",
      "0 0.0999999999985448 [0.09524015]\n",
      "1 0.1999999999970896 [0.11808356]\n",
      "2 0.29999999999563437 [0.22578543]\n",
      "3 0.29999999999563437 [0.21278049]\n",
      "4 0.3999999999941792 [0.46639234]\n",
      "5 0.3999999999941792 [0.4734066]\n",
      "6 0.3999999999941792 [0.49321902]\n",
      "7 0.3999999999941792 [0.49429533]\n",
      "8 0.3999999999941792 [0.48412853]\n",
      "9 0.3999999999941792 [0.4898251]\n",
      "10 0.49999999999999994 [0.53551424]\n",
      "11 0.5999999999985447 [0.6991249]\n",
      "12 0.5999999999985447 [0.8048015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.6999999999970895 [0.83321637]\n",
      "14 0.6999999999970895 [0.87787646]\n",
      "15 0.7999999999956343 [0.8903784]\n",
      "16 0.8999999999941791 [0.87552124]\n",
      "17 0.9999999999999999 [0.79632396]\n",
      "18 1.0999999999985446 [0.8009866]\n",
      "19 1.0999999999985446 [0.7912691]\n",
      "20 1.0999999999985446 [0.77161103]\n",
      "21 1.0999999999985446 [0.74910575]\n",
      "22 1.0999999999985446 [0.70646214]\n",
      "23 1.1999999999970894 [0.7147568]\n",
      "24 1.399999999994179 [0.86684436]\n",
      "25 1.4999999999999998 [0.94766194]\n",
      "26 1.4999999999999998 [0.9663872]\n",
      "27 1.4999999999999998 [0.97337925]\n",
      "28 1.4999999999999998 [1.0380176]\n",
      "29 1.5999999999985446 [1.0909711]\n",
      "testY 30\n",
      "0 0.0 [0.01710333]\n",
      "1 0.0999999999985448 [-0.04029832]\n",
      "2 0.1999999999970896 [0.10547988]\n",
      "3 0.29999999999563437 [0.06636613]\n",
      "4 0.40000000000145514 [0.23099698]\n",
      "5 0.49999999999999994 [0.3823817]\n",
      "6 0.5999999999985447 [0.257878]\n",
      "7 0.6999999999970895 [0.44087642]\n",
      "8 0.7999999999956343 [0.5414576]\n",
      "9 0.7999999999956343 [0.5906604]\n",
      "10 0.9000000000014551 [0.6417439]\n",
      "11 0.9999999999999999 [0.7469651]\n",
      "12 1.0999999999985446 [0.7819331]\n",
      "13 1.0999999999985446 [0.7399222]\n",
      "14 1.0999999999985446 [0.6975979]\n",
      "15 1.0999999999985446 [0.65996236]\n",
      "16 1.0999999999985446 [0.617926]\n",
      "17 1.1999999999970894 [0.62148756]\n",
      "18 1.2999999999956342 [0.6213672]\n",
      "19 1.400000000001455 [0.7533331]\n",
      "20 1.4999999999999998 [0.8966479]\n",
      "21 1.5999999999985446 [0.95660096]\n",
      "22 1.6999999999970894 [1.006347]\n",
      "23 1.6999999999970894 [1.1046621]\n",
      "24 1.900000000001455 [1.1810044]\n",
      "25 1.9999999999999998 [1.2809067]\n",
      "26 2.0999999999985444 [1.4145272]\n",
      "27 2.199999999997089 [1.4125764]\n",
      "28 2.299999999995634 [1.6013298]\n",
      "29 2.4000000000014547 [1.793543]\n",
      "testY 31\n",
      "0 0.0999999999985448 [0.0528339]\n",
      "1 0.29999999999563437 [0.21206985]\n",
      "2 0.3999999999941792 [0.3224279]\n",
      "3 0.49999999999999994 [0.30582276]\n",
      "4 0.6999999999970895 [0.3444801]\n",
      "5 0.7999999999956343 [0.68366665]\n",
      "6 0.7999999999956343 [0.5339857]\n",
      "7 0.8999999999941791 [0.73355097]\n",
      "8 0.9999999999999999 [0.97720784]\n",
      "9 1.0999999999985446 [1.0111325]\n",
      "10 1.0999999999985446 [0.9239412]\n",
      "11 1.1999999999970894 [1.1203972]\n",
      "12 1.399999999994179 [1.3273903]\n",
      "13 1.4999999999999998 [1.5491529]\n",
      "14 1.4999999999999998 [1.6123282]\n",
      "15 1.4999999999999998 [1.6319323]\n",
      "16 1.5999999999985446 [1.6034076]\n",
      "17 1.6999999999970894 [1.7490253]\n",
      "18 1.899999999994179 [1.9404113]\n",
      "19 1.9999999999999998 [1.9958935]\n",
      "20 2.0999999999985444 [2.0049732]\n",
      "21 2.199999999997089 [2.093558]\n",
      "22 2.299999999995634 [2.2070837]\n",
      "23 2.399999999994179 [2.2999706]\n",
      "24 2.4999999999999996 [2.348168]\n",
      "25 2.5999999999985444 [2.4011824]\n",
      "26 2.799999999995634 [2.511467]\n",
      "27 2.899999999994179 [2.606542]\n",
      "28 2.9999999999999996 [2.579353]\n",
      "29 3.0999999999985444 [2.6530926]\n",
      "testY 32\n",
      "0 0.1999999999970896 [0.10500725]\n",
      "1 0.29999999999563437 [0.15164298]\n",
      "2 0.40000000000145514 [0.40926543]\n",
      "3 0.49999999999999994 [0.39545298]\n",
      "4 0.5999999999985447 [0.55731785]\n",
      "5 0.7999999999956343 [0.64330906]\n",
      "6 0.9000000000014551 [0.65772915]\n",
      "7 1.0999999999985446 [0.81675285]\n",
      "8 1.0999999999985446 [0.919913]\n",
      "9 1.2999999999956342 [1.1567276]\n",
      "10 1.400000000001455 [1.0219847]\n",
      "11 1.4999999999999998 [1.1951344]\n",
      "12 1.5999999999985446 [1.5295149]\n",
      "13 1.6999999999970894 [1.4569736]\n",
      "14 1.6999999999970894 [1.5386369]\n",
      "15 1.900000000001455 [1.7252362]\n",
      "16 1.9999999999999998 [1.9673834]\n",
      "17 2.0999999999985444 [2.1349857]\n",
      "18 2.299999999995634 [2.2220376]\n",
      "19 2.4000000000014547 [2.33108]\n",
      "20 2.4999999999999996 [2.482464]\n",
      "21 2.699999999997089 [2.5803986]\n",
      "22 2.799999999995634 [2.7018611]\n",
      "23 2.9000000000014547 [2.7826324]\n",
      "24 3.0999999999985444 [2.769329]\n",
      "25 3.199999999997089 [2.7821522]\n",
      "26 3.299999999995634 [2.7859602]\n",
      "27 3.299999999995634 [2.8940382]\n",
      "28 3.299999999995634 [2.8821712]\n",
      "29 3.299999999995634 [2.878099]\n",
      "testY 33\n",
      "0 0.0 [0.02229965]\n",
      "1 0.0 [0.0157264]\n",
      "2 0.0 [-0.00504303]\n",
      "3 0.0 [-0.03207669]\n",
      "4 0.0 [-0.06022346]\n",
      "5 0.0 [-0.09303064]\n",
      "6 0.0 [-0.12262858]\n",
      "7 0.0 [-0.14996965]\n",
      "8 0.0 [-0.17515288]\n",
      "9 0.0 [-0.19729269]\n",
      "10 0.0 [-0.21781437]\n",
      "11 0.0 [-0.2357572]\n",
      "12 0.0 [-0.25251475]\n",
      "13 0.0 [-0.26707724]\n",
      "14 0.0 [-0.28079748]\n",
      "15 0.0 [-0.292626]\n",
      "16 0.0 [-0.3038794]\n",
      "17 0.0 [-0.31348258]\n",
      "18 0.0 [-0.3217898]\n",
      "19 0.0 [-0.32995534]\n",
      "20 0.0 [-0.33682498]\n",
      "21 0.0 [-0.34270555]\n",
      "22 0.0 [-0.34870553]\n",
      "23 0.0 [-0.35364527]\n",
      "24 0.0 [-0.3578071]\n",
      "25 0.0 [-0.36605036]\n",
      "26 0.0 [-0.37114906]\n",
      "27 0.0 [-0.37592757]\n",
      "28 0.0 [-0.37938666]\n",
      "29 0.0 [-0.38192517]\n",
      "testY 34\n",
      "0 0.0 [0.00333196]\n",
      "1 0.0 [-0.01863529]\n",
      "2 0.0 [-0.05097788]\n",
      "3 0.0 [-0.08605107]\n",
      "4 0.0 [-0.12002472]\n",
      "5 0.0 [-0.15204684]\n",
      "6 0.0 [-0.18054171]\n",
      "7 0.0 [-0.20563336]\n",
      "8 0.0 [-0.22762798]\n",
      "9 0.0 [-0.24688905]\n",
      "10 0.0 [-0.2646033]\n",
      "11 0.0 [-0.27993786]\n",
      "12 0.0 [-0.29331362]\n",
      "13 0.0 [-0.30503488]\n",
      "14 0.0 [-0.31533957]\n",
      "15 0.0 [-0.32442278]\n",
      "16 0.0 [-0.33327672]\n",
      "17 0.0 [-0.3408588]\n",
      "18 0.0 [-0.3474365]\n",
      "19 0.0 [-0.35318106]\n",
      "20 0.0 [-0.35821375]\n",
      "21 0.0 [-0.36263198]\n",
      "22 0.0 [-0.3665158]\n",
      "23 0.0 [-0.37075514]\n",
      "24 0.0 [-0.37423426]\n",
      "25 0.0 [-0.37716013]\n",
      "26 0.0 [-0.37965396]\n",
      "27 0.0 [-0.38179266]\n",
      "28 0.0 [-0.38363516]\n",
      "29 0.0 [-0.38522753]\n",
      "testY 35\n",
      "0 0.0 [-0.00011617]\n",
      "1 0.0 [-0.0249122]\n",
      "2 0.0 [-0.0595109]\n",
      "3 0.0 [-0.0962687]\n",
      "4 0.0 [-0.13140707]\n",
      "5 0.0 [-0.163359]\n",
      "6 0.0 [-0.19170202]\n",
      "7 0.0 [-0.21655096]\n",
      "8 0.0 [-0.23823689]\n",
      "9 0.0 [-0.26178932]\n",
      "10 0.0 [-0.2803508]\n",
      "11 0.0 [-0.29228947]\n",
      "12 0.0 [-0.30796024]\n",
      "13 0.0 [-0.31622925]\n",
      "14 0.0 [-0.32504874]\n",
      "15 0.0 [-0.33668426]\n",
      "16 0.0 [-0.3452318]\n",
      "17 0.0 [-0.3524888]\n",
      "18 0.0 [-0.3586574]\n",
      "19 0.0 [-0.3639196]\n",
      "20 0.0 [-0.3684229]\n",
      "21 0.0 [-0.372289]\n",
      "22 0.0 [-0.3756176]\n",
      "23 0.0 [-0.37925065]\n",
      "24 0.0 [-0.38217252]\n",
      "25 0.0 [-0.38457513]\n",
      "26 0.0 [-0.38658196]\n",
      "27 0.0 [-0.3882711]\n",
      "28 0.0 [-0.38970125]\n",
      "29 0.0 [-0.39091784]\n",
      "testY 36\n",
      "0 0.0 [-0.00570223]\n",
      "1 0.0 [-0.03393691]\n",
      "2 0.0 [-0.0709647]\n",
      "3 0.0 [-0.10932743]\n",
      "4 0.0 [-0.1454118]\n",
      "5 0.0 [-0.17779341]\n",
      "6 0.0 [-0.20617113]\n",
      "7 0.0 [-0.2307611]\n",
      "8 0.0 [-0.25271156]\n",
      "9 0.0 [-0.27146238]\n",
      "10 0.0 [-0.28755262]\n",
      "11 0.0 [-0.3014205]\n",
      "12 0.0 [-0.3134236]\n",
      "13 0.0 [-0.32385615]\n",
      "14 0.0 [-0.33295885]\n",
      "15 0.0 [-0.34092838]\n",
      "16 0.0 [-0.34792572]\n",
      "17 0.0 [-0.35408333]\n",
      "18 0.0 [-0.35951135]\n",
      "19 0.0 [-0.3643016]\n",
      "20 0.0 [-0.36853206]\n",
      "21 0.0 [-0.3722693]\n",
      "22 0.0 [-0.37631083]\n",
      "23 0.0 [-0.37965065]\n",
      "24 0.0 [-0.38246498]\n",
      "25 0.0 [-0.38486785]\n",
      "26 0.0 [-0.386932]\n",
      "27 0.0 [-0.38871324]\n",
      "28 0.0 [-0.3902554]\n",
      "29 0.0 [-0.3809659]\n",
      "testY 37\n",
      "0 0.0 [-0.00841289]\n",
      "1 0.0 [-0.03637221]\n",
      "2 0.0 [-0.07139811]\n",
      "3 0.0 [-0.10695957]\n",
      "4 0.0 [-0.13993606]\n",
      "5 0.0 [-0.16911234]\n",
      "6 0.0 [-0.19426341]\n",
      "7 0.0 [-0.2156341]\n",
      "8 0.0 [-0.23365676]\n",
      "9 0.0 [-0.24880728]\n",
      "10 0.0 [-0.26153794]\n",
      "11 0.0 [-0.2722498]\n",
      "12 0.0 [-0.2812857]\n",
      "13 0.0 [-0.28893286]\n",
      "14 0.0 [-0.29542834]\n",
      "15 0.0 [-0.30096674]\n",
      "16 0.0 [-0.30570707]\n",
      "17 0.0 [-0.309779]\n",
      "18 0.0 [-0.31328833]\n",
      "19 0.0 [-0.31632185]\n",
      "20 0.0 [-0.31895086]\n",
      "21 0.0 [-0.3212344]\n",
      "22 0.0 [-0.3232216]\n",
      "23 0.0 [-0.32495344]\n",
      "24 0.0 [-0.3264645]\n",
      "25 0.0 [-0.32778427]\n",
      "26 0.0 [-0.32893783]\n",
      "27 0.0 [-0.32994664]\n",
      "28 0.0 [-0.33082923]\n",
      "29 0.0 [-0.33160177]\n",
      "testY 38\n",
      "0 0.0 [-0.00841289]\n",
      "1 0.0 [-0.03704956]\n",
      "2 0.0 [-0.07189944]\n",
      "3 0.0 [-0.10734057]\n",
      "4 0.0 [-0.1409456]\n",
      "5 0.0 [-0.17052734]\n",
      "6 0.0 [-0.19593723]\n",
      "7 0.0 [-0.21746472]\n",
      "8 0.0 [-0.18119876]\n",
      "9 0.10000000000582077 [-0.12763341]\n",
      "10 0.20000000000436557 [-0.10758033]\n",
      "11 0.20000000000436557 [-0.10195138]\n",
      "12 0.20000000000436557 [-0.10267367]\n",
      "13 0.20000000000436557 [-0.06583766]\n",
      "14 0.3000000000029104 [0.02149535]\n",
      "15 0.4000000000014552 [0.06013743]\n",
      "16 0.4000000000014552 [0.046248]\n",
      "17 0.6000000000058208 [0.08099803]\n",
      "18 0.7000000000043656 [0.23038796]\n",
      "19 0.8000000000029104 [0.40945387]\n",
      "20 0.9000000000014552 [0.48660064]\n",
      "21 1.0 [0.6270334]\n",
      "22 1.2000000000043656 [0.7980791]\n",
      "23 1.3000000000029104 [0.9582494]\n",
      "24 1.4000000000014552 [1.1747651]\n",
      "25 1.5 [1.2731464]\n",
      "26 1.6000000000058208 [1.36714]\n",
      "27 1.8000000000029104 [1.6330786]\n",
      "28 1.9000000000014552 [1.6734395]\n",
      "29 2.0 [1.7514629]\n",
      "testY 39\n",
      "0 0.10000000000582077 [0.10911]\n",
      "1 0.20000000000436557 [0.15269087]\n",
      "2 0.3000000000029104 [0.19376883]\n",
      "3 0.4000000000014552 [0.24939236]\n",
      "4 0.6000000000058208 [0.5455293]\n",
      "5 0.6000000000058208 [0.46234578]\n",
      "6 0.7000000000043656 [0.59242696]\n",
      "7 0.9000000000014552 [0.7690177]\n",
      "8 1.0 [0.96553177]\n",
      "9 1.1000000000058208 [1.0471865]\n",
      "10 1.2000000000043656 [1.1402855]\n",
      "11 1.3000000000029104 [1.3064137]\n",
      "12 1.3000000000029104 [1.4220941]\n",
      "13 1.3000000000029104 [1.496167]\n",
      "14 1.4000000000014552 [1.4605141]\n",
      "15 1.5 [1.562918]\n",
      "16 1.6000000000058208 [1.7444057]\n",
      "17 1.7000000000043656 [1.9036013]\n",
      "18 1.8000000000029104 [1.7943456]\n",
      "19 2.0 [1.8864202]\n",
      "20 2.1000000000058208 [2.088686]\n",
      "21 2.2000000000043656 [2.0627022]\n",
      "22 2.3000000000029104 [2.1217682]\n",
      "23 2.400000000001455 [2.271073]\n",
      "24 2.5 [2.4657369]\n",
      "25 2.6000000000058208 [2.493548]\n",
      "26 2.7000000000043656 [2.538463]\n",
      "27 2.8000000000029104 [2.5288744]\n",
      "28 3.0 [2.6229959]\n",
      "29 3.1000000000058208 [2.7334576]\n",
      "testY 40\n",
      "0 0.0999999999985448 [0.05867302]\n",
      "1 0.0999999999985448 [0.11486756]\n",
      "2 0.1999999999970896 [0.0517376]\n",
      "3 0.29999999999563437 [0.17582671]\n",
      "4 0.5 [0.15184656]\n",
      "5 0.5999999999985448 [0.31464946]\n",
      "6 0.6999999999970896 [0.4331645]\n",
      "7 0.6999999999970896 [0.4547349]\n",
      "8 0.6999999999970896 [0.4983896]\n",
      "9 0.6999999999970896 [0.5402136]\n",
      "10 0.6999999999970896 [0.64905924]\n",
      "11 0.8999999999941792 [0.7604591]\n",
      "12 1.0 [0.8224674]\n",
      "13 1.0999999999985448 [0.8265076]\n",
      "14 1.0999999999985448 [0.8069363]\n",
      "15 1.0999999999985448 [0.7887466]\n",
      "16 1.0999999999985448 [0.76566964]\n",
      "17 1.0999999999985448 [0.74745613]\n",
      "18 1.0999999999985448 [0.75925]\n",
      "19 1.1999999999970896 [0.8901876]\n",
      "20 1.3999999999941792 [0.9868393]\n",
      "21 1.5 [1.1352596]\n",
      "22 1.5999999999985448 [1.1356968]\n",
      "23 1.5999999999985448 [1.1630006]\n",
      "24 1.5999999999985448 [1.1677098]\n",
      "25 1.5999999999985448 [1.1650257]\n",
      "26 1.5999999999985448 [1.1539109]\n",
      "27 1.5999999999985448 [1.1298745]\n",
      "28 1.5999999999985448 [1.1052989]\n",
      "29 1.5999999999985448 [1.0777044]\n",
      "testY 41\n",
      "0 0.0 [-0.04550079]\n",
      "1 0.0999999999985448 [0.17839004]\n",
      "2 0.1999999999970896 [0.12715645]\n",
      "3 0.29999999999563437 [0.34701502]\n",
      "4 0.40000000000145514 [0.45475376]\n",
      "5 0.40000000000145514 [0.38427842]\n",
      "6 0.40000000000145514 [0.30645525]\n",
      "7 0.49999999999999994 [0.41628963]\n",
      "8 0.49999999999999994 [0.5644316]\n",
      "9 0.5999999999985447 [0.50749046]\n",
      "10 0.5999999999985447 [0.49047688]\n",
      "11 0.5999999999985447 [0.4835863]\n",
      "12 0.5999999999985447 [0.5022928]\n",
      "13 0.6999999999970895 [0.59191304]\n",
      "14 0.7999999999956343 [0.69297105]\n",
      "15 0.9000000000014551 [0.8511002]\n",
      "16 0.9999999999999999 [0.9895702]\n",
      "17 1.0999999999985446 [1.1257665]\n",
      "18 1.1999999999970894 [1.1858292]\n",
      "19 1.2999999999956342 [1.1890779]\n",
      "20 1.2999999999956342 [1.1900775]\n",
      "21 1.400000000001455 [1.2503848]\n",
      "22 1.4999999999999998 [1.2759261]\n",
      "23 1.5999999999985446 [1.3230164]\n",
      "24 1.6999999999970894 [1.315063]\n",
      "25 1.6999999999970894 [1.3051908]\n",
      "26 1.6999999999970894 [1.2941675]\n",
      "27 1.6999999999970894 [1.2071937]\n",
      "28 1.7999999999956342 [1.255704]\n",
      "29 1.7999999999956342 [1.2923863]\n",
      "testY 42\n",
      "0 0.0 [0.05556569]\n",
      "1 0.10000000000582077 [0.07393963]\n",
      "2 0.10000000000582077 [0.03087078]\n",
      "3 0.20000000000436557 [0.17980924]\n",
      "4 0.4000000000014552 [0.2903359]\n",
      "5 0.5 [0.5740674]\n",
      "6 0.6000000000058208 [0.61498153]\n",
      "7 0.6000000000058208 [0.5898584]\n",
      "8 0.6000000000058208 [0.58465993]\n",
      "9 0.6000000000058208 [0.57]\n",
      "10 0.6000000000058208 [0.6227619]\n",
      "11 0.7000000000043656 [0.68213916]\n",
      "12 0.8000000000029104 [0.7378896]\n",
      "13 1.0 [0.7842103]\n",
      "14 1.1000000000058208 [0.7630844]\n",
      "15 1.1000000000058208 [0.7328983]\n",
      "16 1.1000000000058208 [0.743298]\n",
      "17 1.2000000000043656 [0.80154943]\n",
      "18 1.3000000000029104 [0.6705884]\n",
      "19 1.4000000000014552 [0.76521546]\n",
      "20 1.5 [0.86367464]\n",
      "21 1.5 [0.83624643]\n",
      "22 1.6000000000058208 [0.85917646]\n",
      "23 1.6000000000058208 [0.8818535]\n",
      "24 1.6000000000058208 [0.8358823]\n",
      "25 1.7000000000043656 [0.8781075]\n",
      "26 1.8000000000029104 [0.90373373]\n",
      "27 1.9000000000014552 [0.9616791]\n",
      "28 2.0 [1.1485153]\n",
      "29 2.1000000000058208 [1.264168]\n",
      "testY 43\n",
      "0 0.1999999999970896 [0.06176648]\n",
      "1 0.29999999999563437 [0.30404967]\n",
      "2 0.3999999999941792 [0.35916275]\n",
      "3 0.49999999999999994 [0.46124324]\n",
      "4 0.5999999999985447 [0.57522327]\n",
      "5 0.7999999999956343 [0.42522898]\n",
      "6 0.8999999999941791 [0.48234108]\n",
      "7 0.9999999999999999 [0.8134065]\n",
      "8 0.9999999999999999 [0.860975]\n",
      "9 1.0999999999985446 [0.96169454]\n",
      "10 1.2999999999956342 [1.1791074]\n",
      "11 1.399999999994179 [1.5072305]\n",
      "12 1.4999999999999998 [1.5869018]\n",
      "13 1.5999999999985446 [1.8317819]\n",
      "14 1.6999999999970894 [1.8987443]\n",
      "15 1.7999999999956342 [1.818779]\n",
      "16 1.7999999999956342 [1.7794156]\n",
      "17 1.7999999999956342 [1.7382286]\n",
      "18 1.899999999994179 [1.8392595]\n",
      "19 1.899999999994179 [1.7707434]\n",
      "20 1.9999999999999998 [1.8879285]\n",
      "21 2.199999999997089 [2.082112]\n",
      "22 2.199999999997089 [1.9199318]\n",
      "23 2.399999999994179 [2.0689125]\n",
      "24 2.4999999999999996 [2.1746497]\n",
      "25 2.5999999999985444 [2.2922373]\n",
      "26 2.699999999997089 [2.4990854]\n",
      "27 2.699999999997089 [2.5498877]\n",
      "28 2.699999999997089 [2.579699]\n",
      "29 2.699999999997089 [2.585872]\n",
      "testY 44\n",
      "0 0.0999999999985448 [-0.00785502]\n",
      "1 0.1999999999970896 [0.10589861]\n",
      "2 0.3000000000029104 [0.22110032]\n",
      "3 0.5 [0.37307796]\n",
      "4 0.5999999999985448 [0.43108878]\n",
      "5 0.6999999999970896 [0.5075582]\n",
      "6 0.8000000000029104 [0.640353]\n",
      "7 1.0 [0.7107469]\n",
      "8 1.0999999999985448 [1.004436]\n",
      "9 1.1999999999970896 [0.96904397]\n",
      "10 1.3000000000029104 [1.1419458]\n",
      "11 1.5 [1.316533]\n",
      "12 1.5999999999985448 [1.5556285]\n",
      "13 1.6999999999970896 [1.5340108]\n",
      "14 1.8000000000029104 [1.6803582]\n",
      "15 2.0 [1.9698925]\n",
      "16 2.099999999998545 [2.0226371]\n",
      "17 2.1999999999970896 [2.1335163]\n",
      "18 2.3000000000029104 [2.2547123]\n",
      "19 2.5 [2.3254504]\n",
      "20 2.599999999998545 [2.3508332]\n",
      "21 2.6999999999970896 [2.4438553]\n",
      "22 2.900000000001455 [2.5362136]\n",
      "23 3.0 [2.6084986]\n",
      "24 3.1999999999970896 [2.6424384]\n",
      "25 3.3000000000029104 [2.685194]\n",
      "26 3.400000000001455 [2.7429373]\n",
      "27 3.599999999998545 [2.7865736]\n",
      "28 3.6999999999970896 [2.876741]\n",
      "29 3.8000000000029104 [2.820589]\n",
      "testY 45\n",
      "0 0.0999999999985448 [0.16051087]\n",
      "1 0.1999999999970896 [0.13389741]\n",
      "2 0.1999999999970896 [0.130868]\n",
      "3 0.1999999999970896 [0.12472812]\n",
      "4 0.1999999999970896 [0.11625052]\n",
      "5 0.1999999999970896 [0.10527975]\n",
      "6 0.1999999999970896 [0.09325591]\n",
      "7 0.1999999999970896 [0.0807419]\n",
      "8 0.1999999999970896 [0.06809763]\n",
      "9 0.1999999999970896 [0.05562747]\n",
      "10 0.1999999999970896 [0.03881576]\n",
      "11 0.1999999999970896 [0.02463635]\n",
      "12 0.1999999999970896 [0.01233197]\n",
      "13 0.1999999999970896 [0.00092042]\n",
      "14 0.1999999999970896 [-0.0095528]\n",
      "15 0.1999999999970896 [-0.01884202]\n",
      "16 0.1999999999970896 [-0.02734671]\n",
      "17 0.1999999999970896 [-0.03444429]\n",
      "18 0.1999999999970896 [-0.0418736]\n",
      "19 0.1999999999970896 [-0.0472525]\n",
      "20 0.1999999999970896 [-0.05221678]\n",
      "21 0.1999999999970896 [-0.05618856]\n",
      "22 0.1999999999970896 [-0.06008936]\n",
      "23 0.1999999999970896 [-0.06323128]\n",
      "24 0.1999999999970896 [-0.06570596]\n",
      "25 0.1999999999970896 [-0.06846025]\n",
      "26 0.1999999999970896 [-0.07501232]\n",
      "27 0.1999999999970896 [-0.07457047]\n",
      "28 0.1999999999970896 [-0.08052617]\n",
      "29 0.1999999999970896 [-0.08398125]\n",
      "testY 46\n",
      "0 0.0 [-0.0181741]\n",
      "1 0.0 [-0.02819045]\n",
      "2 0.0 [-0.03469478]\n",
      "3 0.0 [-0.04068206]\n",
      "4 0.0 [-0.04751632]\n",
      "5 0.0 [-0.05417242]\n",
      "6 0.0 [-0.04977985]\n",
      "7 0.0 [-0.05443702]\n",
      "8 0.0 [-0.06023338]\n",
      "9 0.0 [-0.06620633]\n",
      "10 0.0 [-0.0726612]\n",
      "11 0.0 [-0.07851481]\n",
      "12 0.0 [-0.08363307]\n",
      "13 0.0 [-0.08809199]\n",
      "14 0.0 [-0.09263214]\n",
      "15 0.0 [-0.0964657]\n",
      "16 0.0 [-0.09960685]\n",
      "17 0.0 [-0.10221561]\n",
      "18 0.0 [-0.10438251]\n",
      "19 0.0 [-0.10686082]\n",
      "20 0.0 [-0.10887431]\n",
      "21 0.0 [-0.11042311]\n",
      "22 0.0 [-0.11165228]\n",
      "23 0.0 [-0.1126326]\n",
      "24 0.0 [-0.11409184]\n",
      "25 0.0 [-0.1152386]\n",
      "26 0.0 [-0.11605091]\n",
      "27 0.0 [-0.11665659]\n",
      "28 0.0 [-0.1171105]\n",
      "29 0.0 [-0.11745072]\n",
      "testY 47\n",
      "0 0.0 [-0.02403443]\n",
      "1 0.0 [-0.03521223]\n",
      "2 0.0 [-0.04228885]\n",
      "3 0.0 [-0.04928548]\n",
      "4 0.0 [-0.05675886]\n",
      "5 0.0 [-0.0643489]\n",
      "6 0.0 [-0.07164992]\n",
      "7 0.0 [-0.07839968]\n",
      "8 0.0 [-0.08886253]\n",
      "9 0.0 [-0.09675378]\n",
      "10 0.0 [-0.0996091]\n",
      "11 0.0 [-0.10680311]\n",
      "12 0.0 [-0.11178044]\n",
      "13 0.0 [-0.11583181]\n",
      "14 0.0 [-0.11916561]\n",
      "15 0.0 [-0.12189382]\n",
      "16 0.0 [-0.12475341]\n",
      "17 0.0 [-0.12705998]\n",
      "18 0.0 [-0.12882034]\n",
      "19 0.0 [-0.1301974]\n",
      "20 0.0 [-0.13127856]\n",
      "21 0.0 [-0.1321287]\n",
      "22 0.0 [-0.13279738]\n",
      "23 0.0 [-0.13332267]\n",
      "24 0.0 [-0.13373464]\n",
      "25 0.0 [-0.13405694]\n",
      "26 0.0 [-0.13493836]\n",
      "27 0.0 [-0.13562985]\n",
      "28 0.0 [-0.13606893]\n",
      "29 0.0 [-0.13636668]\n",
      "testY 48\n",
      "0 0.0 [-0.03013289]\n",
      "1 0.0 [-0.0453527]\n",
      "2 0.0 [-0.05542818]\n",
      "3 0.0 [-0.06465056]\n",
      "4 0.0 [-0.07373399]\n",
      "5 0.0 [-0.08244742]\n",
      "6 0.0 [-0.09114376]\n",
      "7 0.0 [-0.0988568]\n",
      "8 0.0 [-0.10548379]\n",
      "9 0.0 [-0.12178924]\n",
      "10 0.0 [-0.11771782]\n",
      "11 0.0 [-0.13182932]\n",
      "12 0.0 [-0.12514472]\n",
      "13 0.0 [-0.13765982]\n",
      "14 0.0 [-0.14041065]\n",
      "15 0.0 [-0.142336]\n",
      "16 0.0 [-0.14345016]\n",
      "17 0.0 [-0.14400388]\n",
      "18 0.0 [-0.14419247]\n",
      "19 0.0 [-0.14415444]\n",
      "20 0.0 [-0.14398687]\n",
      "21 0.0 [-0.14375569]\n",
      "22 0.0 [-0.14350374]\n",
      "23 0.0 [-0.14391746]\n",
      "24 0.0 [-0.1442023]\n",
      "25 0.0 [-0.14430015]\n",
      "26 0.0 [-0.1443113]\n",
      "27 0.0 [-0.14427647]\n",
      "28 0.0 [-0.14421874]\n",
      "29 0.0 [-0.14415158]\n",
      "testY 49\n",
      "0 0.0 [-0.02761082]\n",
      "1 0.0 [-0.04759306]\n",
      "2 0.0 [-0.06303155]\n",
      "3 0.0 [-0.07620027]\n",
      "4 0.0 [-0.08772924]\n",
      "5 0.0 [-0.09772886]\n",
      "6 0.0 [-0.10625338]\n",
      "7 0.0 [-0.11340588]\n",
      "8 0.0 [-0.11999669]\n",
      "9 0.0 [-0.12470429]\n",
      "10 0.0 [-0.1291189]\n",
      "11 0.0 [-0.13271156]\n",
      "12 0.0 [-0.13550924]\n",
      "13 0.0 [-0.13770188]\n",
      "14 0.0 [-0.13941714]\n",
      "15 0.0 [-0.14075586]\n",
      "16 0.0 [-0.14179781]\n",
      "17 0.0 [-0.14260618]\n",
      "18 0.0 [-0.14323144]\n",
      "19 0.0 [-0.14371319]\n",
      "20 0.0 [-0.14408289]\n",
      "21 0.0 [-0.14436498]\n",
      "22 0.0 [-0.14457868]\n",
      "23 0.0 [-0.14473896]\n",
      "24 0.0 [-0.14485747]\n",
      "25 0.0 [-0.1449433]\n",
      "26 0.0 [-0.14500348]\n",
      "27 0.0 [-0.14504367]\n",
      "28 0.0 [-0.14506811]\n",
      "29 0.0 [-0.14508018]\n",
      "testY 50\n",
      "0 0.0 [-0.02881497]\n",
      "1 0.0 [-0.04984384]\n",
      "2 0.0 [-0.06609189]\n",
      "3 0.0 [-0.07982252]\n",
      "4 0.0 [-0.09170469]\n",
      "5 0.0 [-0.10189985]\n",
      "6 0.0 [-0.11050735]\n",
      "7 0.0 [-0.11766518]\n",
      "8 0.0 [-0.12354393]\n",
      "9 0.0 [-0.12832433]\n",
      "10 0.0 [-0.1321796]\n",
      "11 0.0 [-0.13526717]\n",
      "12 0.0 [-0.1377244]\n",
      "13 0.0 [-0.13966937]\n",
      "14 0.0 [-0.141201]\n",
      "15 0.0 [-0.14240162]\n",
      "16 0.0 [-0.14333875]\n",
      "17 0.0 [-0.1440671]\n",
      "18 0.0 [-0.14463097]\n",
      "19 0.0 [-0.14506547]\n",
      "20 0.0 [-0.14539842]\n",
      "21 0.0 [-0.14565189]\n",
      "22 0.0 [-0.14584306]\n",
      "23 0.0 [-0.14598544]\n",
      "24 0.0 [-0.14608963]\n",
      "25 0.0 [-0.14616363]\n",
      "26 0.0 [-0.14621411]\n",
      "27 0.0 [-0.14624609]\n",
      "28 0.0 [-0.14626348]\n",
      "29 0.0 [-0.14626952]\n",
      "testY 51\n",
      "0 0.0 [-0.02881497]\n",
      "1 0.0 [0.00966256]\n",
      "2 0.0 [0.01806041]\n",
      "3 0.0 [0.01526139]\n",
      "4 0.0999999999985448 [0.03233133]\n",
      "5 0.1999999999970896 [0.12378905]\n",
      "6 0.3000000000029104 [0.14622699]\n",
      "7 0.4000000000014552 [0.18181711]\n",
      "8 0.5 [0.18569095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.5999999999985448 [0.27347553]\n",
      "10 0.6999999999970896 [0.37412]\n",
      "11 0.8000000000029104 [0.44560885]\n",
      "12 0.9000000000014552 [0.5513981]\n",
      "13 1.0999999999985448 [0.61302596]\n",
      "14 1.1999999999970896 [0.8148617]\n",
      "15 1.3000000000029104 [1.0016463]\n",
      "16 1.4000000000014552 [1.0719748]\n",
      "17 1.5 [1.238628]\n",
      "18 1.5999999999985448 [1.2658124]\n",
      "19 1.8000000000029104 [1.3631343]\n",
      "20 1.9000000000014552 [1.514406]\n",
      "21 2.0 [1.692054]\n",
      "22 2.099999999998545 [1.7610892]\n",
      "23 2.1999999999970896 [1.9652792]\n",
      "24 2.400000000001455 [1.9076695]\n",
      "25 2.5 [1.9715532]\n",
      "26 2.599999999998545 [2.1387477]\n",
      "27 2.6999999999970896 [2.1023867]\n",
      "28 2.8000000000029104 [1.8368309]\n",
      "29 2.900000000001455 [1.9445032]\n",
      "testY 52\n",
      "0 0.0999999999985448 [0.11320022]\n",
      "1 0.1999999999970896 [0.02805155]\n",
      "2 0.29999999999563437 [0.07775322]\n",
      "3 0.40000000000145514 [0.27423257]\n",
      "4 0.49999999999999994 [0.45481372]\n",
      "5 0.6999999999970895 [0.6091228]\n",
      "6 0.7999999999956343 [0.7114435]\n",
      "7 0.9000000000014551 [0.7566912]\n",
      "8 0.9999999999999999 [1.0000039]\n",
      "9 1.0999999999985446 [1.1069642]\n",
      "10 1.1999999999970894 [1.2347842]\n",
      "11 1.2999999999956342 [1.3917537]\n",
      "12 1.4999999999999998 [1.441555]\n",
      "13 1.5999999999985446 [1.4360904]\n",
      "14 1.6999999999970894 [1.4990819]\n",
      "15 1.7999999999956342 [1.6490993]\n",
      "16 1.9999999999999998 [1.8256109]\n",
      "17 2.0999999999985444 [2.043167]\n",
      "18 2.199999999997089 [1.9993125]\n",
      "19 2.299999999995634 [2.1227837]\n",
      "20 2.4999999999999996 [2.2185667]\n",
      "21 2.5999999999985444 [2.301536]\n",
      "22 2.5999999999985444 [2.2263496]\n",
      "23 2.5999999999985444 [2.1761255]\n",
      "24 2.5999999999985444 [2.1317244]\n",
      "25 2.5999999999985444 [2.084]\n",
      "26 2.699999999997089 [2.0086784]\n",
      "27 2.799999999995634 [2.0297697]\n",
      "28 2.9000000000014547 [2.1589117]\n",
      "29 2.9999999999999996 [2.1856523]\n",
      "testY 53\n",
      "0 0.0 [0.01594374]\n",
      "1 0.0 [0.03774161]\n",
      "2 0.0 [0.058088]\n",
      "3 0.0999999999985448 [0.12932113]\n",
      "4 0.1999999999970896 [0.30528653]\n",
      "5 0.29999999999563437 [0.48414582]\n",
      "6 0.40000000000145514 [0.64015144]\n",
      "7 0.49999999999999994 [0.69874513]\n",
      "8 0.49999999999999994 [0.70462114]\n",
      "9 0.49999999999999994 [0.7102425]\n",
      "10 0.49999999999999994 [0.69835323]\n",
      "11 0.49999999999999994 [0.6829529]\n",
      "12 0.49999999999999994 [0.6621526]\n",
      "13 0.49999999999999994 [0.63222915]\n",
      "14 0.49999999999999994 [0.679709]\n",
      "15 0.5999999999985447 [0.71340925]\n",
      "16 0.6999999999970895 [0.82059544]\n",
      "17 0.7999999999956343 [0.8689431]\n",
      "18 0.9000000000014551 [0.909825]\n",
      "19 0.9999999999999999 [0.94647735]\n",
      "20 0.9999999999999999 [0.97381705]\n",
      "21 0.9999999999999999 [1.0016843]\n",
      "22 0.9999999999999999 [1.0014067]\n",
      "23 1.0999999999985446 [1.2113658]\n",
      "24 1.1999999999970894 [1.3041686]\n",
      "25 1.1999999999970894 [1.3620372]\n",
      "26 1.1999999999970894 [1.4089149]\n",
      "27 1.1999999999970894 [1.4367086]\n",
      "28 1.2999999999956342 [1.3100402]\n",
      "29 1.400000000001455 [1.4710857]\n",
      "testY 54\n",
      "0 0.0999999999985448 [0.0490711]\n",
      "1 0.29999999999563437 [0.14740755]\n",
      "2 0.3999999999941792 [0.333412]\n",
      "3 0.3999999999941792 [0.34723353]\n",
      "4 0.3999999999941792 [0.3730505]\n",
      "5 0.3999999999941792 [0.3863808]\n",
      "6 0.3999999999941792 [0.38265318]\n",
      "7 0.49999999999999994 [0.4760574]\n",
      "8 0.49999999999999994 [0.5433685]\n",
      "9 0.5999999999985447 [0.638897]\n",
      "10 0.6999999999970895 [0.7419751]\n",
      "11 0.7999999999956343 [0.9201682]\n",
      "12 0.7999999999956343 [0.99069697]\n",
      "13 0.7999999999956343 [1.0571408]\n",
      "14 0.8999999999941791 [1.1097351]\n",
      "15 0.8999999999941791 [1.2285826]\n",
      "16 0.9999999999999999 [1.3657691]\n",
      "17 1.1999999999970894 [1.4880856]\n",
      "18 1.2999999999956342 [1.611695]\n",
      "19 1.399999999994179 [1.6519824]\n",
      "20 1.4999999999999998 [1.7731972]\n",
      "21 1.6999999999970894 [1.9014826]\n",
      "22 1.7999999999956342 [2.0060923]\n",
      "23 1.899999999994179 [2.1185236]\n",
      "24 1.9999999999999998 [2.1600232]\n",
      "25 1.9999999999999998 [2.16038]\n",
      "26 2.0999999999985444 [1.9838232]\n",
      "27 2.199999999997089 [2.0785336]\n",
      "28 2.299999999995634 [2.2682652]\n",
      "29 2.399999999994179 [2.4080787]\n",
      "testY 55\n",
      "0 0.10000000000582077 [0.042995]\n",
      "1 0.20000000000436557 [0.21307124]\n",
      "2 0.3000000000029104 [0.34785903]\n",
      "3 0.4000000000014552 [0.45166975]\n",
      "4 0.4000000000014552 [0.33564314]\n",
      "5 0.5 [0.5089629]\n",
      "6 0.6000000000058208 [0.6640859]\n",
      "7 0.8000000000029104 [0.82978696]\n",
      "8 0.9000000000014552 [1.0548178]\n",
      "9 1.0 [0.90340894]\n",
      "10 1.1000000000058208 [1.0541455]\n",
      "11 1.3000000000029104 [1.2223673]\n",
      "12 1.4000000000014552 [1.1004059]\n",
      "13 1.6000000000058208 [1.2188869]\n",
      "14 1.7000000000043656 [1.2877599]\n",
      "15 1.8000000000029104 [1.4520185]\n",
      "16 2.0 [1.4753118]\n",
      "17 2.1000000000058208 [1.6517227]\n",
      "18 2.3000000000029104 [1.791009]\n",
      "19 2.400000000001455 [2.0450907]\n",
      "20 2.5 [2.1074314]\n",
      "21 2.6000000000058208 [1.9429495]\n",
      "22 2.8000000000029104 [2.1492589]\n",
      "23 2.900000000001455 [2.4041202]\n",
      "24 3.0 [2.3301463]\n",
      "25 3.1000000000058208 [2.3275187]\n",
      "26 3.2000000000043656 [2.563983]\n",
      "27 3.3000000000029104 [2.4391718]\n",
      "28 3.3000000000029104 [2.584012]\n",
      "29 3.3000000000029104 [2.6315103]\n"
     ]
    }
   ],
   "source": [
    "for index,y in enumerate(TestY):\n",
    "    print(\"testY\",index)\n",
    "    for iindex,i in enumerate(y):\n",
    "        print(iindex,i,pred[index][iindex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = pred.cumsum()\n",
    "print(\"测试集\",number,\"的预测结果是：\",pred[-1],\"真实结果是\",df.iloc[-1].milegap)\n",
    "diff=pred[-1]-df.iloc[-1].milegap\n",
    "print(\"相差：\",diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集 0 的预测结果是： 77.99046 真实结果是 83.79999999999562\n",
      "测试集 1 的预测结果是： 111.402596 真实结果是 114.39999999999418\n",
      "测试集 2 的预测结果是： 136.91974 真实结果是 121.0\n",
      "测试集 3 的预测结果是： 89.098885 真实结果是 96.59999999999854\n",
      "测试集 4 的预测结果是： 120.759254 真实结果是 117.80000000000292\n",
      "测试集 5 的预测结果是： 115.27554 真实结果是 121.30000000000292\n",
      "测试集 6 的预测结果是： 107.13007 真实结果是 115.5\n"
     ]
    }
   ],
   "source": [
    "difflist=[]\n",
    "for number,df in enumerate(testdflist):\n",
    "    TestX=[]\n",
    "    TestY=[]\n",
    "    X=df.loc[:,inputfeature].to_numpy()\n",
    "    y=df.loc[:,outputfeature].to_numpy()\n",
    "    lens=len(df)\n",
    "    for index in range(TimeStep,lens):\n",
    "        if(int(index % TimeStep)==0):\n",
    "            TestX.append(X[index-TimeStep:index])\n",
    "            TestY.append(y[index-TimeStep:index].cumsum())\n",
    "    TestX=np.array(TestX)\n",
    "    TestY=np.array(TestY)\n",
    "    pred = single_step_model.predict(TestX)\n",
    "    pred = pred.cumsum()\n",
    "    print(\"测试集\",number,\"的预测结果是：\",pred[-1],\"真实结果是\",df.iloc[-1].milegap)\n",
    "    diff=pred[-1]-df.iloc[-1].milegap\n",
    "    difflist.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PathName=r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\\RNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 21.62283286524353\n"
     ]
    }
   ],
   "source": [
    "MSE=sum(np.array(difflist)**2)**(1/2)\n",
    "print(\"MSE:\",MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(filename, inputfeature,outputfeature,TimeStep,MSE,model):\n",
    "    fh = open(filename, 'w', encoding='utf-8')\n",
    "    fh.write(\"inputfeature:\")\n",
    "    for string in inputfeature:\n",
    "        fh.write(string)\n",
    "    fh.write('\\r')\n",
    "    fh.write(\"outputfeature:\")\n",
    "    for string in outputfeature:\n",
    "        fh.write(string)\n",
    "    fh.write('\\r')\n",
    "    fh.write(\"TimeStep:\")\n",
    "    fh.write(str(TimeStep))\n",
    "    fh.write('\\r')\n",
    "    fh.write(\"MSE:\")\n",
    "    fh.write(str(MSE))\n",
    "    fh.write('\\r')\n",
    "    fh.write(\"model:\")\n",
    "    fh.write(model)\n",
    "    fh.write('\\r')\n",
    "    fh.close()\n",
    "save(PathName+\"\\\\1stDemo.txt\",inputfeature,outputfeature,TimeStep,MSE,\"LSTM(32),Dense(1),optimizer=tf.keras.optimizers.RMSprop(), loss='mae'\")\n",
    "#single_step_model.compile(loss='mean_squared_error', optimizer=Adam(lr = 0.001) , metrics = ['mean_squared_error'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不用TimeStep的RNN（最后输出）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RNNX=[]\n",
    "RNNY=[]\n",
    "for df in traindflist:\n",
    "    X=df.loc[:,inputfeature].to_numpy()\n",
    "    y=df.loc[:,outputfeature].to_numpy().sum()\n",
    "    RNNX.append(X)\n",
    "    RNNY.append(y)\n",
    "RNNX=np.array(RNNX)\n",
    "RNNY=np.array(RNNY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Useless code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#对一个数据集df的数据进行RNN输入化处理\n",
    "X=df.loc[:,inputfeature].to_numpy()\n",
    "y=df.loc[:,outputfeature].to_numpy()\n",
    "newX=X.reshape(X.shape[0],1,X.shape[1])\n",
    "lens=len(newX)\n",
    "RNNX=[]\n",
    "for index,x in enumerate(newX):\n",
    "    if(index<lens-TimeStep):\n",
    "        RNNX.append(X[index:index+TimeStep])\n",
    "    else:\n",
    "        break\n",
    "RNNX=np.array(RNNX)\n",
    "RNNY=[]\n",
    "for index,i in enumerate(y):\n",
    "    if(index<lens-TimeStep):\n",
    "        RNNY.append(y[index:index+TimeStep].sum()*100)\n",
    "    else:\n",
    "        break\n",
    "RNNY=np.array(RNNY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
