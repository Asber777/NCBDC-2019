{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get train data (use for train & test )\n",
    "path = lambda number:r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\Data\\NormaliezdData\\NormlizedTrainData\"+'\\\\'+str(number)+\".csv\"\n",
    "traindflist=[]\n",
    "DFSIZE=158\n",
    "for i in range(DFSIZE):\n",
    "    df=pd.read_csv( path(i) ).iloc[:,1:]\n",
    "    traindflist.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get test data\n",
    "path = lambda number:r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\Data\\NormaliezdData\\NormilizedTestData\"+'\\\\'+str(number)+\".csv\"\n",
    "testdflist=[]\n",
    "DFSIZE=52\n",
    "for i in range(DFSIZE):\n",
    "    df=pd.read_csv( path(i) ).iloc[:,1:]\n",
    "    testdflist.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputfeature=['total_voltage', 'total_current', 'soc', 'temp_max', 'temp_min',\n",
    "       'motor_voltage', 'motor_current', 'total_P', 'motor_P',\n",
    "       'tempMAXMINdiff', 'SOCgap']\n",
    "outputfeature=['milediff']\n",
    "TimeStep=24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 带TimeStep的LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNX=[]\n",
    "RNNY=[]\n",
    "for df in traindflist:\n",
    "    X=df.loc[:,inputfeature].to_numpy()\n",
    "    y=df.loc[:,outputfeature].to_numpy()\n",
    "    lens=len(df)\n",
    "    for index in range(TimeStep,lens):\n",
    "        RNNX.append(X[index-TimeStep:index])\n",
    "        RNNY.append(y[index-TimeStep:index].sum())\n",
    "RNNX=np.array(RNNX)\n",
    "RNNY=np.array(RNNY)\n",
    "RNNX.shape,RNNY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分为测试集和训练集（可没有此步 ，因为我们有选择测试数据集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #这里是引用了交叉验证\n",
    "X_train,X_test, y_train, y_test = train_test_split(RNNX,RNNY,test_size = 0.1,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(X_train.shape , y_train.shape , X_test.shape , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=RNNX\n",
    "y_train=RNNY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , BatchNormalization , Dropout , Activation\n",
    "from keras.layers import LSTM , GRU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.optimizers import Adam , SGD , RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lr_reduce 设置损失不减则降低学习率\n",
    "### checkPoint设置保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PathName=r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\\RNN\"\n",
    "filepath=PathName+\"\\\\3rd_weights.hdf5\"\n",
    "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, epsilon=0.0001, patience=1, verbose=1)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置模型输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE=100\n",
    "BATCH_SIZE=25\n",
    "train_data_single = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_single = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "val_data_single = val_data_single.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  设置模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape=X_train.shape[-2:]\n",
    "\n",
    "single_step_model = tf.keras.models.Sequential()\n",
    "\n",
    "single_step_model.add(tf.keras.layers.LSTM(32,\n",
    "                                           input_shape=input_shape))\n",
    "single_step_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "single_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
    "#single_step_model.compile(loss='mean_squared_error', optimizer=Adam(lr = 0.009) , metrics = ['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=30\n",
    "EVALUATION_INTERVAL=500\n",
    "time_start=time.time()\n",
    "single_step_history = single_step_model.fit(train_data_single, epochs=EPOCHS,\n",
    "                                            steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                            validation_data=val_data_single,\n",
    "                                            validation_steps=50,callbacks = [checkpoint , lr_reduce])\n",
    "time_end=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('totally cost',time_end-time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画出模型loss曲线 查看收敛效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(single_step_history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (如果有)对上面分出来的测试数据测试（非我们小组定义的测试数据集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = single_step_model.predict(X_test)\n",
    "pred,pred.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对指定测试集的数据查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=0\n",
    "df=testdflist[number]\n",
    "TestX=[]\n",
    "TestY=[]\n",
    "X=df.loc[:,inputfeature].to_numpy()\n",
    "y=df.loc[:,outputfeature].to_numpy()\n",
    "lens=len(df)\n",
    "for index in range(TimeStep,lens):\n",
    "    if(int(index % TimeStep)==0):\n",
    "        TestX.append(X[index-TimeStep:index])\n",
    "        TestY.append(y[index-TimeStep:index].sum())\n",
    "TestX=np.array(TestX)\n",
    "TestY=np.array(TestY)\n",
    "pred = single_step_model.predict(TestX)\n",
    "pred = pred.cumsum()\n",
    "print(\"测试集\",number,\"的预测结果是：\",pred[-1],\"真实结果是\",df.iloc[-1].milegap)\n",
    "diff=pred[-1]-df.iloc[-1].milegap\n",
    "print(\"相差：\",diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "difflist=[]\n",
    "for number,df in enumerate(testdflist):\n",
    "    TestX=[]\n",
    "    TestY=[]\n",
    "    X=df.loc[:,inputfeature].to_numpy()\n",
    "    y=df.loc[:,outputfeature].to_numpy()\n",
    "    lens=len(df)\n",
    "    for index in range(TimeStep,lens):\n",
    "        if(int(index % TimeStep)==0):\n",
    "            TestX.append(X[index-TimeStep:index])\n",
    "            TestY.append(y[index-TimeStep:index])\n",
    "    TestX=np.array(TestX)\n",
    "    TestY=np.array(TestY)\n",
    "    pred = single_step_model.predict(TestX)\n",
    "    pred = pred.cumsum()\n",
    "    print(\"测试集\",number,\"的预测结果是：\",pred[-1],\"真实结果是\",df.iloc[-1].milegap)\n",
    "    diff=pred[-1]-df.iloc[-1].milegap\n",
    "    difflist.append(diff/df.iloc[-1].milegap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PathName=r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\\RNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MSE=(sum(np.array(difflist)**2)/52)**(1/2)\n",
    "print(\"MSE:\",MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(filename, inputfeature,outputfeature,TimeStep,MSE,model):\n",
    "    fh = open(filename, 'w', encoding='utf-8')\n",
    "    fh.write(\"inputfeature:\")\n",
    "    for string in inputfeature:\n",
    "        fh.write(string)\n",
    "    fh.write('\\r')\n",
    "    fh.write(\"outputfeature:\")\n",
    "    for string in outputfeature:\n",
    "        fh.write(string)\n",
    "    fh.write('\\r')\n",
    "    fh.write(\"TimeStep:\")\n",
    "    fh.write(str(TimeStep))\n",
    "    fh.write('\\r')\n",
    "    fh.write(\"MSE:\")\n",
    "    fh.write(str(MSE))\n",
    "    fh.write('\\r')\n",
    "    fh.write(\"model:\")\n",
    "    fh.write(model)\n",
    "    fh.write('\\r')\n",
    "    fh.close()\n",
    "save(PathName+\"\\\\3rdDemo.txt\",inputfeature,outputfeature,TimeStep,MSE,\"LSTM(32),Dense(1),optimizer=tf.keras.optimizers.RMSprop(), loss='mae'\")\n",
    "#single_step_model.compile(loss='mean_squared_error', optimizer=Adam(lr = 0.001) , metrics = ['mean_squared_error'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Useless code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#对一个数据集df的数据进行RNN输入化处理\n",
    "X=df.loc[:,inputfeature].to_numpy()\n",
    "y=df.loc[:,outputfeature].to_numpy()\n",
    "newX=X.reshape(X.shape[0],1,X.shape[1])\n",
    "lens=len(newX)\n",
    "RNNX=[]\n",
    "for index,x in enumerate(newX):\n",
    "    if(index<lens-TimeStep):\n",
    "        RNNX.append(X[index:index+TimeStep])\n",
    "    else:\n",
    "        break\n",
    "RNNX=np.array(RNNX)\n",
    "RNNY=[]\n",
    "for index,i in enumerate(y):\n",
    "    if(index<lens-TimeStep):\n",
    "        RNNY.append(y[index:index+TimeStep].sum()*100)\n",
    "    else:\n",
    "        break\n",
    "RNNY=np.array(RNNY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
