{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get train data (use for train & test )\n",
    "path = lambda number:r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\Data\\NormaliezdData\\SmallSizeData\\SmallSizeTrainData\"+'\\\\'+str(number)+\".csv\"\n",
    "traindflist=[]\n",
    "DFSIZE=24\n",
    "for i in range(DFSIZE):\n",
    "    df=pd.read_csv( path(i) ).iloc[:,1:]\n",
    "    traindflist.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get test data\n",
    "path = lambda number:r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\Data\\NormaliezdData\\SmallSizeData\\SmallSizeTestData\"+'\\\\'+str(number)+\".csv\"\n",
    "testdflist=[]\n",
    "DFSIZE=7\n",
    "for i in range(DFSIZE):\n",
    "    df=pd.read_csv( path(i) ).iloc[:,1:]\n",
    "    testdflist.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputfeature=['total_voltage', 'total_current', 'soc', 'temp_max', 'temp_min',\n",
    "       'motor_voltage', 'motor_current', 'total_P', 'motor_P',\n",
    "       'tempMAXMINdiff', 'SOCgap']\n",
    "outputfeature=['milegap']\n",
    "TimeStep=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 带TimeStep的LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RNNX=[]\n",
    "RNNY=[]\n",
    "for df in traindflist:\n",
    "    X=df.loc[:,inputfeature].to_numpy()\n",
    "    y=df.loc[:,outputfeature].to_numpy()\n",
    "    lens=len(df)\n",
    "    for index in range(lens):\n",
    "        if(index<=lens-TimeStep):\n",
    "            RNNX.append(X[index:index+TimeStep])\n",
    "            RNNY.append(y[index:index+TimeStep])\n",
    "            #RNNY.append(y[index:index+TimeStep])\n",
    "        else:\n",
    "            break\n",
    "RNNX=np.array(RNNX)\n",
    "RNNY=np.array(RNNY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1],\n",
       "       [0.2],\n",
       "       [0.2],\n",
       "       [0.2],\n",
       "       [0.3],\n",
       "       [0.4],\n",
       "       [0.5],\n",
       "       [0.6],\n",
       "       [0.7],\n",
       "       [0.7],\n",
       "       [0.7],\n",
       "       [0.8],\n",
       "       [1. ],\n",
       "       [1.1],\n",
       "       [1.2],\n",
       "       [1.3],\n",
       "       [1.4],\n",
       "       [1.6],\n",
       "       [1.7],\n",
       "       [1.8],\n",
       "       [1.9],\n",
       "       [2.1],\n",
       "       [2.2],\n",
       "       [2.3],\n",
       "       [2.4],\n",
       "       [2.4],\n",
       "       [2.4],\n",
       "       [2.5],\n",
       "       [2.6],\n",
       "       [2.7]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNNY[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分为测试集和训练集（可没有此步 ，因为我们有选择测试数据集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #这里是引用了交叉验证\n",
    "X_train,X_test, y_train, y_test = train_test_split(RNNX,RNNY,test_size = 0.2,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37280, 30, 11) (37280, 30, 1) (9321, 30, 11) (9321, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape , y_train.shape , X_test.shape , y_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X_train=RNNX\n",
    "y_train=RNNY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , BatchNormalization , Dropout , Activation\n",
    "from keras.layers import LSTM , GRU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.optimizers import Adam , SGD , RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lr_reduce 设置损失不减则降低学习率\n",
    "### checkPoint设置保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "PathName=r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\\RNN\"\n",
    "filepath=PathName+\"\\\\2ndl_weights.hdf5\"\n",
    "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, epsilon=0.0001, patience=1, verbose=1)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置模型输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE=100\n",
    "BATCH_SIZE=25\n",
    "train_data_single = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_single = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "val_data_single = val_data_single.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  设置模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape=X_train.shape[-2:]\n",
    "input_shape=[None,len(inputfeature)]\n",
    "\n",
    "single_step_model = tf.keras.models.Sequential()\n",
    "\n",
    "single_step_model.add(tf.keras.layers.LSTM(32,\n",
    "                                           input_shape=input_shape))\n",
    "single_step_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "single_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
    "#single_step_model.compile(loss='mean_squared_error', optimizer=Adam(lr = 0.001) , metrics = ['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 200 steps, validate for 50 steps\n",
      "Epoch 1/10\n",
      "195/200 [============================>.] - ETA: 0s - loss: 0.0506\n",
      "Epoch 00001: val_loss improved from -inf to 0.04394, saving model to C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\\RNN\\2ndl_weights.hdf5\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.0506 - val_loss: 0.0439\n",
      "Epoch 2/10\n",
      "196/200 [============================>.] - ETA: 0s - loss: 0.0441\n",
      "Epoch 00002: val_loss did not improve from 0.04394\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0440 - val_loss: 0.0387\n",
      "Epoch 3/10\n",
      "197/200 [============================>.] - ETA: 0s - loss: 0.0413\n",
      "Epoch 00003: val_loss did not improve from 0.04394\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0413 - val_loss: 0.0404\n",
      "Epoch 4/10\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0364\n",
      "Epoch 00004: val_loss did not improve from 0.04394\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0364 - val_loss: 0.0357\n",
      "Epoch 5/10\n",
      "197/200 [============================>.] - ETA: 0s - loss: 0.0359\n",
      "Epoch 00005: val_loss did not improve from 0.04394\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.0359 - val_loss: 0.0355\n",
      "Epoch 6/10\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0355\n",
      "Epoch 00006: val_loss did not improve from 0.04394\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0355 - val_loss: 0.0354\n",
      "Epoch 7/10\n",
      "198/200 [============================>.] - ETA: 0s - loss: 0.0353\n",
      "Epoch 00007: val_loss did not improve from 0.04394\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.0353 - val_loss: 0.0351\n",
      "Epoch 8/10\n",
      "197/200 [============================>.] - ETA: 0s - loss: 0.0349\n",
      "Epoch 00008: val_loss did not improve from 0.04394\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.0350 - val_loss: 0.0351\n",
      "Epoch 9/10\n",
      "198/200 [============================>.] - ETA: 0s - loss: 0.0355\n",
      "Epoch 00009: val_loss did not improve from 0.04394\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0354 - val_loss: 0.0351\n",
      "Epoch 10/10\n",
      "196/200 [============================>.] - ETA: 0s - loss: 0.0348\n",
      "Epoch 00010: val_loss did not improve from 0.04394\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0348 - val_loss: 0.0351\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "EVALUATION_INTERVAL=200\n",
    "single_step_history = single_step_model.fit(train_data_single, epochs=EPOCHS,\n",
    "                                            steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                            validation_data=val_data_single,\n",
    "                                            validation_steps=50,callbacks = [checkpoint , lr_reduce])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画出模型loss曲线 查看收敛效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJGZm1if/PzVGpYTjiQuLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16701624d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(single_step_history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (如果有)对上面分出来的测试数据测试（非我们小组定义的测试数据集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.89303726e-01,  1.78124093e+00,  6.06457857e-01,\n",
       "         2.22495484e+00,  1.93767454e+00, -2.10345689e-03,\n",
       "         2.31087233e+00,  1.80788374e+00,  2.33848802e+00,\n",
       "         9.62209699e-02, -5.21232429e-01],\n",
       "       [ 2.76927069e-01,  3.43991897e-01,  6.06457857e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  1.58816577e-01,\n",
       "        -4.23685146e-01,  3.55720847e-01, -4.21657050e-01,\n",
       "         9.62209699e-02, -5.21232429e-01],\n",
       "       [ 5.39797097e-01,  3.43991897e-01,  6.06457857e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  2.39276595e-01,\n",
       "         3.28945353e-01,  3.57823625e-01,  3.41996544e-01,\n",
       "         9.62209699e-02, -5.21232429e-01],\n",
       "       [ 8.37716462e-01, -6.82614558e-01,  6.06457857e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.00196629e-01,\n",
       "        -7.24737346e-01, -6.84757057e-01, -7.28904590e-01,\n",
       "         9.62209699e-02, -5.21232429e-01],\n",
       "       [-3.36436330e-01,  3.07476507e+00,  6.06457857e-01,\n",
       "         2.22495484e+00,  1.93767454e+00, -2.43483508e-01,\n",
       "         4.79471453e-01,  3.09571842e+00,  4.85644745e-01,\n",
       "         9.62209699e-02, -5.21232429e-01],\n",
       "       [ 2.76927069e-01,  5.08248930e-01,  6.06457857e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  7.83565603e-02,\n",
       "         5.04559136e-01,  5.21918187e-01,  5.17091540e-01,\n",
       "         9.62209699e-02, -5.21232429e-01],\n",
       "       [ 1.36729720e-01,  1.16527706e+00,  6.06457857e-01,\n",
       "         2.22495484e+00,  1.93767454e+00, -2.10345689e-03,\n",
       "         1.25718964e+00,  1.18433998e+00,  1.27509231e+00,\n",
       "         9.62209699e-02, -5.21232429e-01],\n",
       "       [ 2.76927069e-01,  5.28781059e-01,  6.06457857e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  7.83565603e-02,\n",
       "         5.04559136e-01,  5.42692855e-01,  5.17091540e-01,\n",
       "         9.62209699e-02, -5.21232429e-01],\n",
       "       [ 1.41603052e+00, -2.22252424e+00,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  7.22036697e-01,\n",
       "        -2.70666433e+00, -2.26363958e+00, -2.76591588e+00,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 2.06828395e-01,  6.93038092e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  7.83565603e-02,\n",
       "         7.55435969e-01,  7.08064660e-01,  7.70756021e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 4.17124417e-01, -8.71828139e-02,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  1.58816577e-01,\n",
       "         2.78931534e-02, -8.00798874e-02,  3.57940640e-02,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 3.99599748e-01,  1.26793771e+00,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  7.83565603e-02,\n",
       "         1.40771574e+00,  1.29278880e+00,  1.43028367e+00,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 3.15817093e-02,  1.37059835e+00,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00, -8.25634740e-02,\n",
       "         1.55824184e+00,  1.38976581e+00,  1.57535695e+00,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 1.15316049e+00, -2.03773508e+00,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  5.61116663e-01,\n",
       "        -2.55613823e+00, -2.06971672e+00, -2.60298158e+00,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 8.55241130e-01, -3.54100492e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.00196629e-01,\n",
       "        -3.23334413e-01, -3.50360843e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 8.55241130e-01, -2.10375589e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.00196629e-01,\n",
       "        -3.23334413e-01, -2.04038649e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 9.07815136e-01, -3.74632621e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.00196629e-01,\n",
       "        -3.23334413e-01, -3.71252332e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 9.25339804e-01, -3.74632621e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.80656646e-01,\n",
       "        -3.23334413e-01, -3.71248438e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 9.42864473e-01, -3.74632621e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.80656646e-01,\n",
       "        -3.23334413e-01, -3.71244544e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 9.60389141e-01, -3.74632621e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.80656646e-01,\n",
       "        -3.23334413e-01, -3.71240650e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 9.77913810e-01, -3.74632621e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.80656646e-01,\n",
       "        -3.23334413e-01, -3.71236756e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 9.95438478e-01, -3.74632621e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.80656646e-01,\n",
       "        -3.23334413e-01, -3.71232862e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 9.95438478e-01, -3.74632621e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.80656646e-01,\n",
       "        -3.23334413e-01, -3.71232862e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 1.01296315e+00, -3.74632621e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.80656646e-01,\n",
       "        -3.23334413e-01, -3.71228968e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 1.01296315e+00, -3.74632621e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.80656646e-01,\n",
       "        -3.23334413e-01, -3.71228968e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 1.03048782e+00, -3.74632621e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.80656646e-01,\n",
       "        -3.23334413e-01, -3.71225074e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 1.03048782e+00, -3.74632621e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.80656646e-01,\n",
       "        -3.23334413e-01, -3.71225074e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 1.04801248e+00, -3.74632621e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.80656646e-01,\n",
       "        -3.23334413e-01, -3.71221180e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 1.04801248e+00, -3.74632621e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.80656646e-01,\n",
       "        -3.23334413e-01, -3.71221180e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01],\n",
       "       [ 1.04801248e+00, -3.74632621e-01,  5.54803464e-01,\n",
       "         2.22495484e+00,  1.93767454e+00,  4.80656646e-01,\n",
       "        -3.23334413e-01, -3.71221180e-01, -3.20001247e-01,\n",
       "         9.62209699e-02, -4.69063228e-01]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.04185315],\n",
       "        [0.09369189],\n",
       "        [0.12179582],\n",
       "        ...,\n",
       "        [0.0883505 ],\n",
       "        [0.06885304],\n",
       "        [0.07852691]], dtype=float32), (9321, 1), (9321, 30, 11))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = single_step_model.predict(X_test)\n",
    "pred,pred.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对指定测试集的数据查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集 0 的预测结果是： 77.99046 真实结果是 83.79999999999562\n",
      "相差： -5.809536743159683\n"
     ]
    }
   ],
   "source": [
    "number=0\n",
    "df=testdflist[number]\n",
    "TestX=[]\n",
    "TestY=[]\n",
    "X=df.loc[:,inputfeature].to_numpy()\n",
    "y=df.loc[:,outputfeature].to_numpy()\n",
    "lens=len(df)\n",
    "for index in range(TimeStep,lens):\n",
    "    if(int(index % TimeStep)==0):\n",
    "        TestX.append(X[index-TimeStep:index])\n",
    "        TestY.append(y[index-TimeStep:index])\n",
    "TestX=np.array(TestX)\n",
    "TestY=np.array(TestY)\n",
    "pred = single_step_model.predict(TestX)\n",
    "pred = pred.cumsum()\n",
    "print(\"测试集\",number,\"的预测结果是：\",pred[-1],\"真实结果是\",df.iloc[-1].milegap)\n",
    "diff=pred[-1]-df.iloc[-1].milegap\n",
    "print(\"相差：\",diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集 0 的预测结果是： 77.99046 真实结果是 83.79999999999562\n",
      "测试集 1 的预测结果是： 111.402596 真实结果是 114.39999999999418\n",
      "测试集 2 的预测结果是： 136.91974 真实结果是 121.0\n",
      "测试集 3 的预测结果是： 89.098885 真实结果是 96.59999999999854\n",
      "测试集 4 的预测结果是： 120.759254 真实结果是 117.80000000000292\n",
      "测试集 5 的预测结果是： 115.27554 真实结果是 121.30000000000292\n",
      "测试集 6 的预测结果是： 107.13007 真实结果是 115.5\n"
     ]
    }
   ],
   "source": [
    "difflist=[]\n",
    "for number,df in enumerate(testdflist):\n",
    "    TestX=[]\n",
    "    TestY=[]\n",
    "    X=df.loc[:,inputfeature].to_numpy()\n",
    "    y=df.loc[:,outputfeature].to_numpy()\n",
    "    lens=len(df)\n",
    "    for index in range(TimeStep,lens):\n",
    "        if(int(index % TimeStep)==0):\n",
    "            TestX.append(X[index-TimeStep:index])\n",
    "            TestY.append(y[index-TimeStep:index])\n",
    "    TestX=np.array(TestX)\n",
    "    TestY=np.array(TestY)\n",
    "    pred = single_step_model.predict(TestX)\n",
    "    pred = pred.cumsum()\n",
    "    print(\"测试集\",number,\"的预测结果是：\",pred[-1],\"真实结果是\",df.iloc[-1].milegap)\n",
    "    diff=pred[-1]-df.iloc[-1].milegap\n",
    "    difflist.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PathName=r\"C:\\Users\\14020\\Desktop\\NCBDC 2019\\model\\RNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 21.62283286524353\n"
     ]
    }
   ],
   "source": [
    "MSE=sum(np.array(difflist)**2)**(1/2)\n",
    "print(\"MSE:\",MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(filename, inputfeature,outputfeature,TimeStep,MSE,model):\n",
    "    fh = open(filename, 'w', encoding='utf-8')\n",
    "    fh.write(\"inputfeature:\")\n",
    "    for string in inputfeature:\n",
    "        fh.write(string)\n",
    "    fh.write('\\r')\n",
    "    fh.write(\"outputfeature:\")\n",
    "    for string in outputfeature:\n",
    "        fh.write(string)\n",
    "    fh.write('\\r')\n",
    "    fh.write(\"TimeStep:\")\n",
    "    fh.write(str(TimeStep))\n",
    "    fh.write('\\r')\n",
    "    fh.write(\"MSE:\")\n",
    "    fh.write(str(MSE))\n",
    "    fh.write('\\r')\n",
    "    fh.write(\"model:\")\n",
    "    fh.write(model)\n",
    "    fh.write('\\r')\n",
    "    fh.close()\n",
    "save(PathName+\"\\\\1stDemo.txt\",inputfeature,outputfeature,TimeStep,MSE,\"LSTM(32),Dense(1),optimizer=tf.keras.optimizers.RMSprop(), loss='mae'\")\n",
    "#single_step_model.compile(loss='mean_squared_error', optimizer=Adam(lr = 0.001) , metrics = ['mean_squared_error'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不用TimeStep的RNN（最后输出）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RNNX=[]\n",
    "RNNY=[]\n",
    "for df in traindflist:\n",
    "    X=df.loc[:,inputfeature].to_numpy()\n",
    "    y=df.loc[:,outputfeature].to_numpy().sum()\n",
    "    RNNX.append(X)\n",
    "    RNNY.append(y)\n",
    "RNNX=np.array(RNNX)\n",
    "RNNY=np.array(RNNY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Useless code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#对一个数据集df的数据进行RNN输入化处理\n",
    "X=df.loc[:,inputfeature].to_numpy()\n",
    "y=df.loc[:,outputfeature].to_numpy()\n",
    "newX=X.reshape(X.shape[0],1,X.shape[1])\n",
    "lens=len(newX)\n",
    "RNNX=[]\n",
    "for index,x in enumerate(newX):\n",
    "    if(index<lens-TimeStep):\n",
    "        RNNX.append(X[index:index+TimeStep])\n",
    "    else:\n",
    "        break\n",
    "RNNX=np.array(RNNX)\n",
    "RNNY=[]\n",
    "for index,i in enumerate(y):\n",
    "    if(index<lens-TimeStep):\n",
    "        RNNY.append(y[index:index+TimeStep].sum()*100)\n",
    "    else:\n",
    "        break\n",
    "RNNY=np.array(RNNY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
